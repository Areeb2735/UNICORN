{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:261: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:391: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/CT-CLIP/CT_CLIP/ct_clip/ct_clip.py:596: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt = torch.load(str(path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CTCLIP(\n",
       "  (text_transformer): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (visual_transformer): CTViT(\n",
       "    (spatial_rel_pos_bias): ContinuousPositionBias(\n",
       "      (net): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (2): Linear(in_features=512, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (to_patch_emb_first_frame): Sequential(\n",
       "      (0): Rearrange('b c 1 (h p1) (w p2) -> b 1 h w (c p1 p2)', p1=20, p2=20)\n",
       "      (1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Linear(in_features=400, out_features=512, bias=True)\n",
       "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (to_patch_emb): Sequential(\n",
       "      (0): Rearrange('b c (t pt) (h p1) (w p2) -> b t h w (c pt p1 p2)', p1=20, p2=20, pt=10)\n",
       "      (1): LayerNorm((4000,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Linear(in_features=4000, out_features=512, bias=True)\n",
       "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (enc_spatial_transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x ModuleList(\n",
       "          (0): PEG(\n",
       "            (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "            (context_norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "          )\n",
       "          (2): None\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "            (2): GEGLU()\n",
       "            (3): Dropout(p=0.0, inplace=False)\n",
       "            (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm()\n",
       "    )\n",
       "    (enc_temporal_transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x ModuleList(\n",
       "          (0): PEG(\n",
       "            (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "            (context_norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "          )\n",
       "          (2): None\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "            (2): GEGLU()\n",
       "            (3): Dropout(p=0.0, inplace=False)\n",
       "            (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm()\n",
       "    )\n",
       "    (vq): VectorQuantize(\n",
       "      (project_in): Identity()\n",
       "      (project_out): Identity()\n",
       "      (_codebook): CosineSimCodebook()\n",
       "    )\n",
       "    (to_pixels_first_frame): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=400, bias=True)\n",
       "      (1): Rearrange('b 1 h w (c p1 p2) -> b c 1 (h p1) (w p2)', p1=20, p2=20)\n",
       "    )\n",
       "    (to_pixels): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=4000, bias=True)\n",
       "      (1): Rearrange('b t h w (c pt p1 p2) -> b c (t pt) (h p1) (w p2)', p1=20, p2=20, pt=10)\n",
       "    )\n",
       "  )\n",
       "  (to_text_latent): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (to_visual_latent): Linear(in_features=294912, out_features=512, bias=False)\n",
       "  (to_text_latent_extra): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (to_visual_latent_extra): Linear(in_features=294912, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prognosis_model import emb_gen, model_lora\n",
    "from data_inference_hector import Hector_Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "\n",
    "from ct_clip import CTCLIP\n",
    "from transformer_maskgit import CTViT\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from lifelines.utils import concordance_index\n",
    "from data_inference_hector import Hector_Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('microsoft/BiomedVLP-CXR-BERT-specialized',do_lower_case=True)\n",
    "text_encoder = BertModel.from_pretrained(\"microsoft/BiomedVLP-CXR-BERT-specialized\")\n",
    "\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "text_encoder.to(device)\n",
    "\n",
    "image_encoder = CTViT(\n",
    "    dim = 512,\n",
    "    codebook_size = 8192,\n",
    "    image_size = 480,\n",
    "    patch_size = 20,\n",
    "    temporal_patch_size = 10,\n",
    "    spatial_depth = 4,\n",
    "    temporal_depth = 4,\n",
    "    dim_head = 32,\n",
    "    heads = 8\n",
    ")\n",
    "\n",
    "image_encoder.to(device)\n",
    "\n",
    "clip = CTCLIP(\n",
    "    image_encoder = image_encoder,\n",
    "    text_encoder = text_encoder,\n",
    "    dim_image = 294912,\n",
    "    dim_text = 768,\n",
    "    dim_latent = 512,\n",
    "    extra_latent_projection = False,         # whether to use separate projections for text-to-image vs image-to-text comparisons (CLOOB)\n",
    "    use_mlm=False,\n",
    "    downsample_image_embeds = False,\n",
    "    use_all_token_embeds = False,\n",
    ")\n",
    "\n",
    "clip.load(\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/CT-CLIP_v2.pt\")\n",
    "clip.to(device)\n",
    "\n",
    "# model = emb_gen(clip, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hect_dataset = Hector_Dataset(data_folder = \"/share/sda/mohammadqazi/project/hector/pre_processed/\",  \n",
    "                csv_file =\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/TNM_hector_prompts.csv\")\n",
    "\n",
    "loader = DataLoader(hect_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================\n",
       "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #\n",
       "=======================================================================================================================================\n",
       "emb_gen                                                      --                        [8, 512]                  --\n",
       "├─CTCLIP: 1-1                                                --                        [8, 24, 24, 512]          302,776,321\n",
       "│    └─BertModel: 2-1                                        [8, 512]                  [8, 768]                  --\n",
       "│    │    └─BertEmbeddings: 3-1                              --                        [8, 512, 768]             --\n",
       "│    │    │    └─Embedding: 4-1                              [8, 512]                  [8, 512, 768]             23,440,896\n",
       "│    │    │    └─Embedding: 4-2                              [8, 512]                  [8, 512, 768]             1,536\n",
       "│    │    │    └─Embedding: 4-3                              [1, 512]                  [1, 512, 768]             393,216\n",
       "│    │    │    └─LayerNorm: 4-4                              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    └─Dropout: 4-5                                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    └─BertEncoder: 3-2                                 [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    └─ModuleList: 4-6                             --                        --                        --\n",
       "│    │    │    │    └─BertLayer: 5-1                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-1                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-1       [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-1             [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-2             [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-3             [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-4            [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-2          [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-5             [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-6            [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-7          [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-2             [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-3                  [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-4          [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-3                   [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-5                  [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-6                 [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-7               [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-2                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-4                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-8       [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-8             [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-9             [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-10            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-11           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-9          [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-12            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-13           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-14         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-5             [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-10                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-11         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-6                   [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-12                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-13                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-14              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-3                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-7                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-15      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-15            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-16            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-17            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-18           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-16         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-19            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-20           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-21         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-8             [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-17                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-18         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-9                   [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-19                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-20                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-21              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-4                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-10               [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-22      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-22            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-23            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-24            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-25           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-23         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-26            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-27           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-28         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-11            [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-24                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-25         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-12                  [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-26                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-27                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-28              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-5                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-13               [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-29      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-29            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-30            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-31            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-32           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-30         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-33            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-34           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-35         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-14            [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-31                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-32         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-15                  [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-33                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-34                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-35              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-6                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-16               [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-36      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-36            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-37            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-38            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-39           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-37         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-40            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-41           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-42         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-17            [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-38                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-39         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-18                  [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-40                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-41                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-42              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-7                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-19               [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-43      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-43            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-44            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-45            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-46           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-44         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-47            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-48           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-49         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-20            [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-45                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-46         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-21                  [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-47                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-48                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-49              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-8                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-22               [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-50      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-50            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-51            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-52            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-53           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-51         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-54            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-55           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-56         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-23            [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-52                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-53         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-24                  [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-54                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-55                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-56              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-9                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-25               [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-57      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-57            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-58            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-59            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-60           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-58         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-61            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-62           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-63         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-26            [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-59                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-60         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-27                  [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-61                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-62                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-63              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-10                        [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-28               [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-64      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-64            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-65            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-66            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-67           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-65         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-68            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-69           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-70         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-29            [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-66                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-67         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-30                  [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-68                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-69                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-70              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-11                        [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-31               [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-71      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-71            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-72            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-73            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-74           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-72         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-75            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-76           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-77         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-32            [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-73                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-74         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-33                  [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-75                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-76                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-77              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-12                        [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-34               [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-78      [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-78            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-79            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-80            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-81           [8, 12, 512, 512]         [8, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-79         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-82            [8, 512, 768]             [8, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-83           [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-84         [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-35            [8, 512, 768]             [8, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-80                 [8, 512, 768]             [8, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-81         [8, 512, 3072]            [8, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-36                  [8, 512, 3072]            [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-82                 [8, 512, 3072]            [8, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-83                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-84              [8, 512, 768]             [8, 512, 768]             1,536\n",
       "│    │    └─BertPooler: 3-3                                  [8, 512, 768]             [8, 768]                  --\n",
       "│    │    │    └─Linear: 4-7                                 [8, 768]                  [8, 768]                  590,592\n",
       "│    │    │    └─Tanh: 4-8                                   [8, 768]                  [8, 768]                  --\n",
       "│    └─CTViT: 2-2                                            [8, 1, 240, 480, 480]     [8, 24, 24, 24, 512]      13,014,352\n",
       "│    │    └─Sequential: 3-4                                  [8, 1, 240, 480, 480]     [8, 24, 24, 24, 512]      --\n",
       "│    │    │    └─Rearrange: 4-9                              [8, 1, 240, 480, 480]     [8, 24, 24, 24, 4000]     --\n",
       "│    │    │    └─LayerNorm: 4-10                             [8, 24, 24, 24, 4000]     [8, 24, 24, 24, 4000]     8,000\n",
       "│    │    │    └─Linear: 4-11                                [8, 24, 24, 24, 4000]     [8, 24, 24, 24, 512]      2,048,512\n",
       "│    │    │    └─LayerNorm: 4-12                             [8, 24, 24, 24, 512]      [8, 24, 24, 24, 512]      1,024\n",
       "│    │    └─ContinuousPositionBias: 3-5                      --                        [8, 576, 576]             --\n",
       "│    │    │    └─ModuleList: 4-13                            --                        --                        --\n",
       "│    │    │    │    └─Sequential: 5-13                       [576, 576, 2]             [576, 576, 512]           --\n",
       "│    │    │    │    │    └─Linear: 6-37                      [576, 576, 2]             [576, 576, 512]           1,536\n",
       "│    │    │    │    │    └─LeakyReLU: 6-38                   [576, 576, 512]           [576, 576, 512]           --\n",
       "│    │    │    │    └─Sequential: 5-14                       [576, 576, 512]           [576, 576, 512]           --\n",
       "│    │    │    │    │    └─Linear: 6-39                      [576, 576, 512]           [576, 576, 512]           262,656\n",
       "│    │    │    │    │    └─LeakyReLU: 6-40                   [576, 576, 512]           [576, 576, 512]           --\n",
       "│    │    │    │    └─Linear: 5-15                           [576, 576, 512]           [576, 576, 8]             4,104\n",
       "│    │    └─Transformer: 3-6                                 [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    └─ModuleList: 4-14                            --                        --                        --\n",
       "│    │    │    │    └─ModuleList: 5-16                       --                        --                        --\n",
       "│    │    │    │    │    └─PEG: 6-41                         [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    │    │    │    └─Conv3d: 7-85                 [8, 512, 26, 26, 26]      [8, 512, 24, 24, 24]      14,336\n",
       "│    │    │    │    │    └─Attention: 6-42                   [192, 576, 512]           [192, 576, 512]           576\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-86              [192, 576, 512]           [192, 576, 512]           512\n",
       "│    │    │    │    │    │    └─Linear: 7-87                 [192, 576, 512]           [192, 576, 256]           131,072\n",
       "│    │    │    │    │    │    └─Linear: 7-88                 [192, 576, 512]           [192, 576, 512]           262,144\n",
       "│    │    │    │    │    │    └─Dropout: 7-89                [192, 8, 576, 576]        [192, 8, 576, 576]        --\n",
       "│    │    │    │    │    │    └─Linear: 7-90                 [192, 576, 256]           [192, 576, 512]           131,072\n",
       "│    │    │    │    │    └─Sequential: 6-43                  [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-91              [192, 576, 512]           [192, 576, 512]           1,024\n",
       "│    │    │    │    │    │    └─Linear: 7-92                 [192, 576, 512]           [192, 576, 2730]          1,397,760\n",
       "│    │    │    │    │    │    └─GEGLU: 7-93                  [192, 576, 2730]          [192, 576, 1365]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-94                [192, 576, 1365]          [192, 576, 1365]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-95                 [192, 576, 1365]          [192, 576, 512]           698,880\n",
       "│    │    │    │    └─ModuleList: 5-17                       --                        --                        --\n",
       "│    │    │    │    │    └─PEG: 6-44                         [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    │    │    │    └─Conv3d: 7-96                 [8, 512, 26, 26, 26]      [8, 512, 24, 24, 24]      14,336\n",
       "│    │    │    │    │    └─Attention: 6-45                   [192, 576, 512]           [192, 576, 512]           576\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-97              [192, 576, 512]           [192, 576, 512]           512\n",
       "│    │    │    │    │    │    └─Linear: 7-98                 [192, 576, 512]           [192, 576, 256]           131,072\n",
       "│    │    │    │    │    │    └─Linear: 7-99                 [192, 576, 512]           [192, 576, 512]           262,144\n",
       "│    │    │    │    │    │    └─Dropout: 7-100               [192, 8, 576, 576]        [192, 8, 576, 576]        --\n",
       "│    │    │    │    │    │    └─Linear: 7-101                [192, 576, 256]           [192, 576, 512]           131,072\n",
       "│    │    │    │    │    └─Sequential: 6-46                  [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-102             [192, 576, 512]           [192, 576, 512]           1,024\n",
       "│    │    │    │    │    │    └─Linear: 7-103                [192, 576, 512]           [192, 576, 2730]          1,397,760\n",
       "│    │    │    │    │    │    └─GEGLU: 7-104                 [192, 576, 2730]          [192, 576, 1365]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-105               [192, 576, 1365]          [192, 576, 1365]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-106                [192, 576, 1365]          [192, 576, 512]           698,880\n",
       "│    │    │    │    └─ModuleList: 5-18                       --                        --                        --\n",
       "│    │    │    │    │    └─PEG: 6-47                         [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    │    │    │    └─Conv3d: 7-107                [8, 512, 26, 26, 26]      [8, 512, 24, 24, 24]      14,336\n",
       "│    │    │    │    │    └─Attention: 6-48                   [192, 576, 512]           [192, 576, 512]           576\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-108             [192, 576, 512]           [192, 576, 512]           512\n",
       "│    │    │    │    │    │    └─Linear: 7-109                [192, 576, 512]           [192, 576, 256]           131,072\n",
       "│    │    │    │    │    │    └─Linear: 7-110                [192, 576, 512]           [192, 576, 512]           262,144\n",
       "│    │    │    │    │    │    └─Dropout: 7-111               [192, 8, 576, 576]        [192, 8, 576, 576]        --\n",
       "│    │    │    │    │    │    └─Linear: 7-112                [192, 576, 256]           [192, 576, 512]           131,072\n",
       "│    │    │    │    │    └─Sequential: 6-49                  [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-113             [192, 576, 512]           [192, 576, 512]           1,024\n",
       "│    │    │    │    │    │    └─Linear: 7-114                [192, 576, 512]           [192, 576, 2730]          1,397,760\n",
       "│    │    │    │    │    │    └─GEGLU: 7-115                 [192, 576, 2730]          [192, 576, 1365]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-116               [192, 576, 1365]          [192, 576, 1365]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-117                [192, 576, 1365]          [192, 576, 512]           698,880\n",
       "│    │    │    │    └─ModuleList: 5-19                       --                        --                        --\n",
       "│    │    │    │    │    └─PEG: 6-50                         [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    │    │    │    └─Conv3d: 7-118                [8, 512, 26, 26, 26]      [8, 512, 24, 24, 24]      14,336\n",
       "│    │    │    │    │    └─Attention: 6-51                   [192, 576, 512]           [192, 576, 512]           576\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-119             [192, 576, 512]           [192, 576, 512]           512\n",
       "│    │    │    │    │    │    └─Linear: 7-120                [192, 576, 512]           [192, 576, 256]           131,072\n",
       "│    │    │    │    │    │    └─Linear: 7-121                [192, 576, 512]           [192, 576, 512]           262,144\n",
       "│    │    │    │    │    │    └─Dropout: 7-122               [192, 8, 576, 576]        [192, 8, 576, 576]        --\n",
       "│    │    │    │    │    │    └─Linear: 7-123                [192, 576, 256]           [192, 576, 512]           131,072\n",
       "│    │    │    │    │    └─Sequential: 6-52                  [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-124             [192, 576, 512]           [192, 576, 512]           1,024\n",
       "│    │    │    │    │    │    └─Linear: 7-125                [192, 576, 512]           [192, 576, 2730]          1,397,760\n",
       "│    │    │    │    │    │    └─GEGLU: 7-126                 [192, 576, 2730]          [192, 576, 1365]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-127               [192, 576, 1365]          [192, 576, 1365]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-128                [192, 576, 1365]          [192, 576, 512]           698,880\n",
       "│    │    │    └─LayerNorm: 4-15                             [192, 576, 512]           [192, 576, 512]           512\n",
       "├─AdaptiveAvgPool2d: 1-2                                     [8, 512, 24, 24]          [8, 512, 1, 1]            --\n",
       "=======================================================================================================================================\n",
       "Total params: 438,148,761\n",
       "Trainable params: 438,148,761\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.40\n",
       "=======================================================================================================================================\n",
       "Input size (MB): 1769.57\n",
       "Forward/backward pass size (MB): 32476.55\n",
       "Params size (MB): 489.42\n",
       "Estimated Total Size (MB): 34735.54\n",
       "======================================================================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "img_emb, text, relapse, RFS, _ = next(iter(loader))\n",
    "img_emb = img_emb.to(device)\n",
    "text_tokens = tokenizer(\n",
    "    text, \n",
    "    return_tensors=\"pt\", \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    max_length=512\n",
    ").to(device)\n",
    "relapse = relapse.to(device)\n",
    "RFS = RFS.to(device)\n",
    "summary(model, input_data=[text_tokens,img_emb ], depth=8, col_names=[\"input_size\", \"output_size\", \"num_params\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    inference_mode=False, r=8, lora_alpha=64, lora_dropout=0.2, target_modules=[\"to_q\", \"to_kv\"]\n",
    ")\n",
    "model_peft = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_B.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_A.default.weight\n",
      "base_model.model.clip.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_peft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_lora(\n",
       "  (clip): PeftModel(\n",
       "    (base_model): LoraModel(\n",
       "      (model): CTCLIP(\n",
       "        (text_transformer): BertModel(\n",
       "          (embeddings): BertEmbeddings(\n",
       "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "            (position_embeddings): Embedding(512, 768)\n",
       "            (token_type_embeddings): Embedding(2, 768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "          (encoder): BertEncoder(\n",
       "            (layer): ModuleList(\n",
       "              (0-11): 12 x BertLayer(\n",
       "                (attention): BertAttention(\n",
       "                  (self): BertSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.25, inplace=False)\n",
       "                  )\n",
       "                  (output): BertSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.25, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): BertIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): BertOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.25, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (pooler): BertPooler(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (activation): Tanh()\n",
       "          )\n",
       "        )\n",
       "        (visual_transformer): CTViT(\n",
       "          (spatial_rel_pos_bias): ContinuousPositionBias(\n",
       "            (net): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): LeakyReLU(negative_slope=0.1)\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (1): LeakyReLU(negative_slope=0.1)\n",
       "              )\n",
       "              (2): Linear(in_features=512, out_features=8, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (to_patch_emb_first_frame): Sequential(\n",
       "            (0): Rearrange('b c 1 (h p1) (w p2) -> b 1 h w (c p1 p2)', p1=20, p2=20)\n",
       "            (1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (2): Linear(in_features=400, out_features=512, bias=True)\n",
       "            (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (to_patch_emb): Sequential(\n",
       "            (0): Rearrange('b c (t pt) (h p1) (w p2) -> b t h w (c pt p1 p2)', p1=20, p2=20, pt=10)\n",
       "            (1): LayerNorm((4000,), eps=1e-05, elementwise_affine=True)\n",
       "            (2): Linear(in_features=4000, out_features=512, bias=True)\n",
       "            (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (enc_spatial_transformer): Transformer(\n",
       "            (layers): ModuleList(\n",
       "              (0-3): 4 x ModuleList(\n",
       "                (0): PEG(\n",
       "                  (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "                )\n",
       "                (1): Attention(\n",
       "                  (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (norm): LayerNorm()\n",
       "                  (context_norm): LayerNorm()\n",
       "                  (to_q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=256, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (to_kv): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "                )\n",
       "                (2): None\n",
       "                (3): Sequential(\n",
       "                  (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "                  (2): GEGLU()\n",
       "                  (3): Dropout(p=0.0, inplace=False)\n",
       "                  (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (norm_out): LayerNorm()\n",
       "          )\n",
       "          (enc_temporal_transformer): Transformer(\n",
       "            (layers): ModuleList(\n",
       "              (0-3): 4 x ModuleList(\n",
       "                (0): PEG(\n",
       "                  (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "                )\n",
       "                (1): Attention(\n",
       "                  (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (norm): LayerNorm()\n",
       "                  (context_norm): LayerNorm()\n",
       "                  (to_q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=256, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (to_kv): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "                )\n",
       "                (2): None\n",
       "                (3): Sequential(\n",
       "                  (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "                  (2): GEGLU()\n",
       "                  (3): Dropout(p=0.0, inplace=False)\n",
       "                  (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (norm_out): LayerNorm()\n",
       "          )\n",
       "          (vq): VectorQuantize(\n",
       "            (project_in): Identity()\n",
       "            (project_out): Identity()\n",
       "            (_codebook): CosineSimCodebook()\n",
       "          )\n",
       "          (to_pixels_first_frame): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=400, bias=True)\n",
       "            (1): Rearrange('b 1 h w (c p1 p2) -> b c 1 (h p1) (w p2)', p1=20, p2=20)\n",
       "          )\n",
       "          (to_pixels): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=4000, bias=True)\n",
       "            (1): Rearrange('b t h w (c pt p1 p2) -> b c (t pt) (h p1) (w p2)', p1=20, p2=20, pt=10)\n",
       "          )\n",
       "        )\n",
       "        (to_text_latent): Linear(in_features=768, out_features=512, bias=False)\n",
       "        (to_visual_latent): Linear(in_features=294912, out_features=512, bias=False)\n",
       "        (to_text_latent_extra): Linear(in_features=768, out_features=512, bias=False)\n",
       "        (to_visual_latent_extra): Linear(in_features=294912, out_features=512, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (img_embd): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (text_embd): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fuse): Sequential(\n",
       "    (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (mtlr): MTLR(in_features=512, num_time_bins=13)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "num_time_bins = 12\n",
    "peft_config = LoraConfig(\n",
    "    inference_mode=False, r=8, lora_alpha=64, lora_dropout=0.2, target_modules=[\"to_q\", \"to_kv\"]\n",
    ")\n",
    "\n",
    "model = model_lora(clip, device, peft_config, num_time_bins)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================================================================================================\n",
       "Layer (type:depth-idx)                                                 Input Shape               Output Shape              Param #\n",
       "=================================================================================================================================================\n",
       "model_lora                                                             --                        [8, 13]                   --\n",
       "├─PeftModel: 1-1                                                       --                        [8, 24, 24, 512]          --\n",
       "│    └─LoraModel: 2-1                                                  --                        --                        --\n",
       "│    │    └─CTCLIP: 3-1                                                --                        [8, 24, 24, 512]          302,776,321\n",
       "│    │    │    └─BertModel: 4-1                                        [8, 512]                  [8, 768]                  --\n",
       "│    │    │    │    └─BertEmbeddings: 5-1                              --                        [8, 512, 768]             --\n",
       "│    │    │    │    │    └─Embedding: 6-1                              [8, 512]                  [8, 512, 768]             (23,440,896)\n",
       "│    │    │    │    │    └─Embedding: 6-2                              [8, 512]                  [8, 512, 768]             (1,536)\n",
       "│    │    │    │    │    └─Embedding: 6-3                              [1, 512]                  [1, 512, 768]             (393,216)\n",
       "│    │    │    │    │    └─LayerNorm: 6-4                              [8, 512, 768]             [8, 512, 768]             (1,536)\n",
       "│    │    │    │    │    └─Dropout: 6-5                                [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    └─BertEncoder: 5-2                                 [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    └─ModuleList: 6-6                             --                        --                        --\n",
       "│    │    │    │    │    │    └─BertLayer: 7-1                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-1                [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-2             [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-3                   [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-2                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-4                [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-5             [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-6                   [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-3                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-7                [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-8             [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-9                   [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-4                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-10               [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-11            [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-12                  [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-5                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-13               [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-14            [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-15                  [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-6                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-16               [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-17            [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-18                  [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-7                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-19               [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-20            [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-21                  [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-8                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-22               [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-23            [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-24                  [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-9                         [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-25               [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-26            [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-27                  [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-10                        [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-28               [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-29            [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-30                  [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-11                        [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-31               [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-32            [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-33                  [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    │    │    └─BertLayer: 7-12                        [8, 512, 768]             [8, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─BertAttention: 8-34               [8, 512, 768]             [8, 512, 768]             (2,363,904)\n",
       "│    │    │    │    │    │    │    └─BertIntermediate: 8-35            [8, 512, 768]             [8, 512, 3072]            (2,362,368)\n",
       "│    │    │    │    │    │    │    └─BertOutput: 8-36                  [8, 512, 3072]            [8, 512, 768]             (2,361,600)\n",
       "│    │    │    │    └─BertPooler: 5-3                                  [8, 512, 768]             [8, 768]                  --\n",
       "│    │    │    │    │    └─Linear: 6-7                                 [8, 768]                  [8, 768]                  (590,592)\n",
       "│    │    │    │    │    └─Tanh: 6-8                                   [8, 768]                  [8, 768]                  --\n",
       "│    │    │    └─CTViT: 4-2                                            [8, 1, 240, 480, 480]     [8, 24, 24, 24, 512]      13,071,696\n",
       "│    │    │    │    └─Sequential: 5-4                                  [8, 1, 240, 480, 480]     [8, 24, 24, 24, 512]      --\n",
       "│    │    │    │    │    └─Rearrange: 6-9                              [8, 1, 240, 480, 480]     [8, 24, 24, 24, 4000]     --\n",
       "│    │    │    │    │    └─LayerNorm: 6-10                             [8, 24, 24, 24, 4000]     [8, 24, 24, 24, 4000]     (8,000)\n",
       "│    │    │    │    │    └─Linear: 6-11                                [8, 24, 24, 24, 4000]     [8, 24, 24, 24, 512]      (2,048,512)\n",
       "│    │    │    │    │    └─LayerNorm: 6-12                             [8, 24, 24, 24, 512]      [8, 24, 24, 24, 512]      (1,024)\n",
       "│    │    │    │    └─ContinuousPositionBias: 5-5                      --                        [8, 576, 576]             --\n",
       "│    │    │    │    │    └─ModuleList: 6-13                            --                        --                        --\n",
       "│    │    │    │    │    │    └─Sequential: 7-13                       [576, 576, 2]             [576, 576, 512]           --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-37                      [576, 576, 2]             [576, 576, 512]           (1,536)\n",
       "│    │    │    │    │    │    │    └─LeakyReLU: 8-38                   [576, 576, 512]           [576, 576, 512]           --\n",
       "│    │    │    │    │    │    └─Sequential: 7-14                       [576, 576, 512]           [576, 576, 512]           --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-39                      [576, 576, 512]           [576, 576, 512]           (262,656)\n",
       "│    │    │    │    │    │    │    └─LeakyReLU: 8-40                   [576, 576, 512]           [576, 576, 512]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-15                           [576, 576, 512]           [576, 576, 8]             (4,104)\n",
       "│    │    │    │    └─Transformer: 5-6                                 [192, 576, 512]           [192, 576, 512]           --\n",
       "│    │    │    │    │    └─ModuleList: 6-14                            --                        --                        --\n",
       "│    │    │    │    │    │    └─ModuleList: 7-16                       --                        --                        --\n",
       "│    │    │    │    │    │    │    └─PEG: 8-41                         [192, 576, 512]           [192, 576, 512]           (14,336)\n",
       "│    │    │    │    │    │    │    └─Attention: 8-42                   [192, 576, 512]           [192, 576, 512]           539,712\n",
       "│    │    │    │    │    │    │    └─Sequential: 8-43                  [192, 576, 512]           [192, 576, 512]           (2,097,664)\n",
       "│    │    │    │    │    │    └─ModuleList: 7-17                       --                        --                        --\n",
       "│    │    │    │    │    │    │    └─PEG: 8-44                         [192, 576, 512]           [192, 576, 512]           (14,336)\n",
       "│    │    │    │    │    │    │    └─Attention: 8-45                   [192, 576, 512]           [192, 576, 512]           539,712\n",
       "│    │    │    │    │    │    │    └─Sequential: 8-46                  [192, 576, 512]           [192, 576, 512]           (2,097,664)\n",
       "│    │    │    │    │    │    └─ModuleList: 7-18                       --                        --                        --\n",
       "│    │    │    │    │    │    │    └─PEG: 8-47                         [192, 576, 512]           [192, 576, 512]           (14,336)\n",
       "│    │    │    │    │    │    │    └─Attention: 8-48                   [192, 576, 512]           [192, 576, 512]           539,712\n",
       "│    │    │    │    │    │    │    └─Sequential: 8-49                  [192, 576, 512]           [192, 576, 512]           (2,097,664)\n",
       "│    │    │    │    │    │    └─ModuleList: 7-19                       --                        --                        --\n",
       "│    │    │    │    │    │    │    └─PEG: 8-50                         [192, 576, 512]           [192, 576, 512]           (14,336)\n",
       "│    │    │    │    │    │    │    └─Attention: 8-51                   [192, 576, 512]           [192, 576, 512]           539,712\n",
       "│    │    │    │    │    │    │    └─Sequential: 8-52                  [192, 576, 512]           [192, 576, 512]           (2,097,664)\n",
       "│    │    │    │    │    └─LayerNorm: 6-15                             [192, 576, 512]           [192, 576, 512]           (512)\n",
       "├─AdaptiveAvgPool2d: 1-2                                               [8, 512, 24, 24]          [8, 512, 1, 1]            --\n",
       "├─Sequential: 1-3                                                      [8, 512]                  [8, 512]                  --\n",
       "│    └─Linear: 2-2                                                     [8, 512]                  [8, 512]                  262,656\n",
       "│    └─GELU: 2-3                                                       [8, 512]                  [8, 512]                  --\n",
       "│    └─Linear: 2-4                                                     [8, 512]                  [8, 512]                  262,656\n",
       "│    └─LayerNorm: 2-5                                                  [8, 512]                  [8, 512]                  1,024\n",
       "├─Sequential: 1-4                                                      [8, 768]                  [8, 512]                  --\n",
       "│    └─Linear: 2-6                                                     [8, 768]                  [8, 512]                  393,728\n",
       "│    └─GELU: 2-7                                                       [8, 512]                  [8, 512]                  --\n",
       "│    └─Linear: 2-8                                                     [8, 512]                  [8, 512]                  262,656\n",
       "│    └─LayerNorm: 2-9                                                  [8, 512]                  [8, 512]                  1,024\n",
       "├─Sequential: 1-5                                                      [8, 1024, 1]              [8, 512, 1]               --\n",
       "│    └─Conv1d: 2-10                                                    [8, 1024, 1]              [8, 512, 1]               1,573,376\n",
       "│    └─GELU: 2-11                                                      [8, 512, 1]               [8, 512, 1]               --\n",
       "│    └─Conv1d: 2-12                                                    [8, 512, 1]               [8, 512, 1]               786,944\n",
       "├─MTLR: 1-6                                                            [8, 512]                  [8, 13]                   6,156\n",
       "=================================================================================================================================================\n",
       "Total params: 441,813,669\n",
       "Trainable params: 3,664,908\n",
       "Non-trainable params: 438,148,761\n",
       "Total mult-adds (G): 9.44\n",
       "=================================================================================================================================================\n",
       "Input size (MB): 1769.57\n",
       "Forward/backward pass size (MB): 35251.34\n",
       "Params size (MB): 503.85\n",
       "Estimated Total Size (MB): 37524.76\n",
       "================================================================================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "hect_dataset = Hector_Dataset(data_folder = \"/share/sda/mohammadqazi/project/hector/pre_processed/\",  \n",
    "                csv_file =\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/TNM_hector_prompts.csv\")\n",
    "\n",
    "loader = DataLoader(hect_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "img_emb, text, relapse, RFS, _ = next(iter(loader))\n",
    "img_emb = img_emb.to(device)\n",
    "text_tokens = tokenizer(\n",
    "    text, \n",
    "    return_tensors=\"pt\", \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    max_length=512\n",
    ").to(device)\n",
    "relapse = relapse.to(device)\n",
    "RFS = RFS.to(device)\n",
    "\n",
    "summary(model, input_data=[text_tokens,img_emb ], depth=8, col_names=[\"input_size\", \"output_size\", \"num_params\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_B.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_A.default.weight\n",
      "clip.base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_B.default.weight\n",
      "img_embd.0.weight\n",
      "img_embd.0.bias\n",
      "img_embd.2.weight\n",
      "img_embd.2.bias\n",
      "img_embd.3.weight\n",
      "img_embd.3.bias\n",
      "text_embd.0.weight\n",
      "text_embd.0.bias\n",
      "text_embd.2.weight\n",
      "text_embd.2.bias\n",
      "text_embd.3.weight\n",
      "text_embd.3.bias\n",
      "fuse.0.weight\n",
      "fuse.0.bias\n",
      "fuse.2.weight\n",
      "fuse.2.bias\n",
      "mtlr.mtlr_weight\n",
      "mtlr.mtlr_bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "class Hector_Dataset_Subset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.samples[index]\n",
    "\n",
    "class Hector_Dataset_emb(Dataset):\n",
    "    def __init__(self, emd_path, csv_file):\n",
    "        self.emd = np.load(emd_path , allow_pickle=True).item()\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.paths=[]\n",
    "        self.samples = self.prepare_samples()\n",
    "        self.nii_to_tensor = partial(self.to_tensor)\n",
    "\n",
    "    def prepare_samples(self):\n",
    "        samples = []\n",
    "\n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            filename = row['PatientID'] + \"_ct_roi.npz\"\n",
    "            # filepath = os.path.join(self.data_folder, filename)\n",
    "            image_embedding = self.emd[filename]['image_embedding']\n",
    "            text_embedding = self.emd[filename]['text_embedding']\n",
    "            fold = row['fold']\n",
    "            samples.append((image_embedding, text_embedding, row['Relapse'], row['RFS'], filename, fold))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def train_val_split(self, fold):\n",
    "        train_samples = []\n",
    "        val_samples = []\n",
    "        for sample in self.samples:\n",
    "            if sample[5] == fold:\n",
    "                val_samples.append(sample)\n",
    "            else:\n",
    "                train_samples.append(sample)\n",
    "        return Hector_Dataset_Subset(train_samples), Hector_Dataset_Subset(val_samples)\n",
    "\n",
    "    def to_tensor(self, emb):\n",
    "        # img_data = np.load(path)['arr_0']\n",
    "        tensor = torch.tensor(emb)\n",
    "        # tensor = tensor.unsqueeze(0)\n",
    "        return tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_embedding, text_embedding, relapse, RFS, filename, fold= self.samples[index]\n",
    "        text_embedding_tensor = self.to_tensor(text_embedding)\n",
    "        image_embedding_tensor = self.to_tensor(image_embedding)\n",
    "        return image_embedding_tensor, text_embedding_tensor, relapse, RFS, filename, fold\n",
    "\n",
    "hect_dataset = Hector_Dataset_emb(emd_path = '/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/embeddings/embeddings.npy',  \n",
    "                csv_file =\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/TNM_hector_prompts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = hect_dataset.train_val_split(fold=0)\n",
    "                            train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 512])\n",
      "torch.Size([64, 768])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([ 903,  591, 1670, 1429, 1354, 1296,  175, 1087,  984, 3534, 5484,  419,\n",
      "        1005, 3606, 1152, 1174, 1307, 3069, 3148, 1000,  195, 2615, 1357,   88,\n",
      "        3533, 3022, 1297, 2856, 1882,  377, 1410, 1299,  888,  996, 2566, 4425,\n",
      "        2858,  762, 1833,  378, 1201, 1459,  929, 2847,  493, 2201,   97,  325,\n",
      "        1080, 2806, 2518, 3861, 5137,  635, 1557,   77, 5116, 2843, 1215, 2562,\n",
      "        1421, 2421, 1081, 1847])\n",
      "('CHUM-030_ct_roi.npz', 'MDA-096_ct_roi.npz', 'MDA-048_ct_roi.npz', 'CHUP-001_ct_roi.npz', 'HMR-040_ct_roi.npz', 'MDA-108_ct_roi.npz', 'CHUP-013_ct_roi.npz', 'CHUM-035_ct_roi.npz', 'MDA-113_ct_roi.npz', 'MDA-078_ct_roi.npz', 'MDA-168_ct_roi.npz', 'CHUS-049_ct_roi.npz', 'CHUS-055_ct_roi.npz', 'MDA-064_ct_roi.npz', 'MDA-067_ct_roi.npz', 'CHUM-019_ct_roi.npz', 'CHUS-073_ct_roi.npz', 'MDA-144_ct_roi.npz', 'MDA-163_ct_roi.npz', 'HGJ-080_ct_roi.npz', 'MDA-194_ct_roi.npz', 'MDA-041_ct_roi.npz', 'MDA-091_ct_roi.npz', 'MDA-201_ct_roi.npz', 'MDA-059_ct_roi.npz', 'HGJ-043_ct_roi.npz', 'CHUM-018_ct_roi.npz', 'MDA-134_ct_roi.npz', 'MDA-179_ct_roi.npz', 'CHUS-051_ct_roi.npz', 'HGJ-036_ct_roi.npz', 'MDA-071_ct_roi.npz', 'CHUM-051_ct_roi.npz', 'MDA-114_ct_roi.npz', 'MDA-130_ct_roi.npz', 'MDA-020_ct_roi.npz', 'MDA-089_ct_roi.npz', 'HGJ-088_ct_roi.npz', 'CHUS-013_ct_roi.npz', 'MDA-083_ct_roi.npz', 'HGJ-073_ct_roi.npz', 'CHUS-045_ct_roi.npz', 'HGJ-071_ct_roi.npz', 'MDA-027_ct_roi.npz', 'HMR-021_ct_roi.npz', 'HGJ-057_ct_roi.npz', 'MDA-124_ct_roi.npz', 'CHUM-061_ct_roi.npz', 'CHUS-078_ct_roi.npz', 'MDA-166_ct_roi.npz', 'MDA-098_ct_roi.npz', 'MDA-036_ct_roi.npz', 'MDA-014_ct_roi.npz', 'HGJ-087_ct_roi.npz', 'CHUS-040_ct_roi.npz', 'MDA-019_ct_roi.npz', 'MDA-016_ct_roi.npz', 'MDA-170_ct_roi.npz', 'CHUM-013_ct_roi.npz', 'MDA-003_ct_roi.npz', 'MDA-123_ct_roi.npz', 'CHUS-016_ct_roi.npz', 'HGJ-077_ct_roi.npz', 'MDA-066_ct_roi.npz')\n",
      "tensor([3, 3, 4, 2, 3, 1, 4, 2, 4, 2, 3, 3, 3, 1, 3, 1, 3, 2, 1, 2, 2, 3, 3, 2,\n",
      "        3, 4, 2, 1, 4, 1, 3, 2, 3, 1, 1, 1, 2, 1, 2, 4, 2, 4, 3, 4, 1, 3, 2, 1,\n",
      "        1, 4, 1, 1, 4, 4, 2, 2, 3, 2, 1, 2, 2, 2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "for img_emb, text_emb, relapse, RFS, filename, fold in train_loader:\n",
    "    print(img_emb.shape)\n",
    "    print(text_emb.shape)\n",
    "    print(relapse)\n",
    "    print(RFS)\n",
    "    print(filename)\n",
    "    print(fold)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Sequential                               [1, 1024]                 [1, 128]                  --\n",
       "├─Linear: 1-1                            [1, 1024]                 [1, 512]                  524,800\n",
       "├─GELU: 1-2                              [1, 512]                  [1, 512]                  --\n",
       "├─Linear: 1-3                            [1, 512]                  [1, 128]                  65,664\n",
       "===================================================================================================================\n",
       "Total params: 590,464\n",
       "Trainable params: 590,464\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.59\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 2.36\n",
       "Estimated Total Size (MB): 2.37\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "model_1 = nn.Sequential(\n",
    "    nn.Linear(512 + 512, 512),\n",
    "    nn.GELU(),\n",
    "    nn.Linear(512, 128),\n",
    ")\n",
    "\n",
    "model_2 = nn.Sequential(\n",
    "    nn.Conv1d(\n",
    "        in_channels=(512 + 512),\n",
    "        out_channels=512,\n",
    "        kernel_size=3,\n",
    "        padding=1,\n",
    "    ),\n",
    "    nn.GELU(),\n",
    "    nn.Conv1d(\n",
    "        in_channels=512,\n",
    "        out_channels=128,\n",
    "        kernel_size=3,\n",
    "        padding=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model_1, input_data=torch.rand(1, 512*2), depth=8, col_names=[\"input_size\", \"output_size\", \"num_params\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Sequential                               [1, 1024, 1]              [1, 128, 1]               --\n",
       "├─Conv1d: 1-1                            [1, 1024, 1]              [1, 512, 1]               1,573,376\n",
       "├─GELU: 1-2                              [1, 512, 1]               [1, 512, 1]               --\n",
       "├─Conv1d: 1-3                            [1, 512, 1]               [1, 128, 1]               196,736\n",
       "===================================================================================================================\n",
       "Total params: 1,770,112\n",
       "Trainable params: 1,770,112\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.77\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 7.08\n",
       "Estimated Total Size (MB): 7.09\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_2, input_data=torch.rand(1, 512+512, 1), depth=8, col_names=[\"input_size\", \"output_size\", \"num_params\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:261: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:391: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/CT-CLIP/CT_CLIP/ct_clip/ct_clip.py:596: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt = torch.load(str(path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CTCLIP(\n",
       "  (text_transformer): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (visual_transformer): CTViT(\n",
       "    (spatial_rel_pos_bias): ContinuousPositionBias(\n",
       "      (net): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (2): Linear(in_features=512, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (to_patch_emb_first_frame): Sequential(\n",
       "      (0): Rearrange('b c 1 (h p1) (w p2) -> b 1 h w (c p1 p2)', p1=20, p2=20)\n",
       "      (1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Linear(in_features=400, out_features=512, bias=True)\n",
       "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (to_patch_emb): Sequential(\n",
       "      (0): Rearrange('b c (t pt) (h p1) (w p2) -> b t h w (c pt p1 p2)', p1=20, p2=20, pt=10)\n",
       "      (1): LayerNorm((4000,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Linear(in_features=4000, out_features=512, bias=True)\n",
       "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (enc_spatial_transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x ModuleList(\n",
       "          (0): PEG(\n",
       "            (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "            (context_norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "          )\n",
       "          (2): None\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "            (2): GEGLU()\n",
       "            (3): Dropout(p=0.0, inplace=False)\n",
       "            (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm()\n",
       "    )\n",
       "    (enc_temporal_transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x ModuleList(\n",
       "          (0): PEG(\n",
       "            (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "            (context_norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "          )\n",
       "          (2): None\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "            (2): GEGLU()\n",
       "            (3): Dropout(p=0.0, inplace=False)\n",
       "            (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm()\n",
       "    )\n",
       "    (vq): VectorQuantize(\n",
       "      (project_in): Identity()\n",
       "      (project_out): Identity()\n",
       "      (_codebook): CosineSimCodebook()\n",
       "    )\n",
       "    (to_pixels_first_frame): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=400, bias=True)\n",
       "      (1): Rearrange('b 1 h w (c p1 p2) -> b c 1 (h p1) (w p2)', p1=20, p2=20)\n",
       "    )\n",
       "    (to_pixels): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=4000, bias=True)\n",
       "      (1): Rearrange('b t h w (c pt p1 p2) -> b c (t pt) (h p1) (w p2)', p1=20, p2=20, pt=10)\n",
       "    )\n",
       "  )\n",
       "  (to_text_latent): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (to_visual_latent): Linear(in_features=294912, out_features=512, bias=False)\n",
       "  (to_text_latent_extra): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (to_visual_latent_extra): Linear(in_features=294912, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import Adam, AdamW\n",
    "from torchinfo import summary\n",
    "\n",
    "from utils import make_time_bins\n",
    "from utils import encode_survival, mtlr_neg_log_likelihood, make_optimizer\n",
    "from utils import mtlr_survival, mtlr_risk, roc_auc_at_times, brier_score_at_times\n",
    "from prognosis_model import model_lora, model_lora_again\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "\n",
    "\n",
    "from ct_clip import CTCLIP\n",
    "from transformer_maskgit import CTViT\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from lifelines.utils import concordance_index\n",
    "from data_inference_hector import Hector_Dataset_lora\n",
    "\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed) \n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('microsoft/BiomedVLP-CXR-BERT-specialized',do_lower_case=True)\n",
    "text_encoder = BertModel.from_pretrained(\"microsoft/BiomedVLP-CXR-BERT-specialized\")\n",
    "\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "text_encoder.to(device)\n",
    "\n",
    "image_encoder = CTViT(\n",
    "    dim = 512,\n",
    "    codebook_size = 8192,\n",
    "    image_size = 480,\n",
    "    patch_size = 20,\n",
    "    temporal_patch_size = 10,\n",
    "    spatial_depth = 4,\n",
    "    temporal_depth = 4,\n",
    "    dim_head = 32,\n",
    "    heads = 8\n",
    ")\n",
    "\n",
    "image_encoder.to(device)\n",
    "\n",
    "clip = CTCLIP(\n",
    "    image_encoder = image_encoder,\n",
    "    text_encoder = text_encoder,\n",
    "    dim_image = 294912,\n",
    "    dim_text = 768,\n",
    "    dim_latent = 512,\n",
    "    extra_latent_projection = False,         # whether to use separate projections for text-to-image vs image-to-text comparisons (CLOOB)\n",
    "    use_mlm=False,\n",
    "    downsample_image_embeds = False,\n",
    "    use_all_token_embeds = False,\n",
    ")\n",
    "\n",
    "clip.load(\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/CT-CLIP_v2.pt\")\n",
    "clip.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"baseline.txt\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for name, module in clip.named_modules():\n",
    "        f.write(name + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    inference_mode=False, r=8, lora_alpha=64, lora_dropout=0.2, target_modules=[\"to_q\", \"to_kv\"]\n",
    ")\n",
    "\n",
    "clip = get_peft_model(clip, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"lora.txt\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for name, module in clip.named_modules():\n",
    "        f.write(name + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): CTCLIP(\n",
       "      (text_transformer): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.25, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.25, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.25, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.25, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (visual_transformer): CTViT(\n",
       "        (spatial_rel_pos_bias): ContinuousPositionBias(\n",
       "          (net): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.1)\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.1)\n",
       "            )\n",
       "            (2): Linear(in_features=512, out_features=8, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (to_patch_emb_first_frame): Sequential(\n",
       "          (0): Rearrange('b c 1 (h p1) (w p2) -> b 1 h w (c p1 p2)', p1=20, p2=20)\n",
       "          (1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): Linear(in_features=400, out_features=512, bias=True)\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (to_patch_emb): Sequential(\n",
       "          (0): Rearrange('b c (t pt) (h p1) (w p2) -> b t h w (c pt p1 p2)', p1=20, p2=20, pt=10)\n",
       "          (1): LayerNorm((4000,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): Linear(in_features=4000, out_features=512, bias=True)\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (enc_spatial_transformer): Transformer(\n",
       "          (layers): ModuleList(\n",
       "            (0-3): 4 x ModuleList(\n",
       "              (0): PEG(\n",
       "                (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "                (norm): LayerNorm()\n",
       "                (context_norm): LayerNorm()\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=512, out_features=256, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.2, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (to_kv): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.2, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "              )\n",
       "              (2): None\n",
       "              (3): Sequential(\n",
       "                (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "                (2): GEGLU()\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norm_out): LayerNorm()\n",
       "        )\n",
       "        (enc_temporal_transformer): Transformer(\n",
       "          (layers): ModuleList(\n",
       "            (0-3): 4 x ModuleList(\n",
       "              (0): PEG(\n",
       "                (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "                (norm): LayerNorm()\n",
       "                (context_norm): LayerNorm()\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=512, out_features=256, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.2, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (to_kv): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.2, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "              )\n",
       "              (2): None\n",
       "              (3): Sequential(\n",
       "                (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "                (2): GEGLU()\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norm_out): LayerNorm()\n",
       "        )\n",
       "        (vq): VectorQuantize(\n",
       "          (project_in): Identity()\n",
       "          (project_out): Identity()\n",
       "          (_codebook): CosineSimCodebook()\n",
       "        )\n",
       "        (to_pixels_first_frame): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=400, bias=True)\n",
       "          (1): Rearrange('b 1 h w (c p1 p2) -> b c 1 (h p1) (w p2)', p1=20, p2=20)\n",
       "        )\n",
       "        (to_pixels): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=4000, bias=True)\n",
       "          (1): Rearrange('b t h w (c pt p1 p2) -> b c (t pt) (h p1) (w p2)', p1=20, p2=20, pt=10)\n",
       "        )\n",
       "      )\n",
       "      (to_text_latent): Linear(in_features=768, out_features=512, bias=False)\n",
       "      (to_visual_latent): Linear(in_features=294912, out_features=512, bias=False)\n",
       "      (to_text_latent_extra): Linear(in_features=768, out_features=512, bias=False)\n",
       "      (to_visual_latent_extra): Linear(in_features=294912, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "base_model\n",
      "base_model.model\n",
      "base_model.model.text_transformer\n",
      "base_model.model.text_transformer.embeddings\n",
      "base_model.model.text_transformer.embeddings.word_embeddings\n",
      "base_model.model.text_transformer.embeddings.position_embeddings\n",
      "base_model.model.text_transformer.embeddings.token_type_embeddings\n",
      "base_model.model.text_transformer.embeddings.LayerNorm\n",
      "base_model.model.text_transformer.embeddings.dropout\n",
      "base_model.model.text_transformer.encoder\n",
      "base_model.model.text_transformer.encoder.layer\n",
      "base_model.model.text_transformer.encoder.layer.0\n",
      "base_model.model.text_transformer.encoder.layer.0.attention\n",
      "base_model.model.text_transformer.encoder.layer.0.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.0.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.0.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.0.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.0.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.0.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.0.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.0.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.0.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.0.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.0.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.0.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.0.output\n",
      "base_model.model.text_transformer.encoder.layer.0.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.0.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.0.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.1\n",
      "base_model.model.text_transformer.encoder.layer.1.attention\n",
      "base_model.model.text_transformer.encoder.layer.1.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.1.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.1.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.1.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.1.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.1.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.1.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.1.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.1.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.1.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.1.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.1.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.1.output\n",
      "base_model.model.text_transformer.encoder.layer.1.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.1.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.1.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.2\n",
      "base_model.model.text_transformer.encoder.layer.2.attention\n",
      "base_model.model.text_transformer.encoder.layer.2.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.2.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.2.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.2.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.2.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.2.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.2.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.2.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.2.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.2.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.2.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.2.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.2.output\n",
      "base_model.model.text_transformer.encoder.layer.2.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.2.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.2.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.3\n",
      "base_model.model.text_transformer.encoder.layer.3.attention\n",
      "base_model.model.text_transformer.encoder.layer.3.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.3.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.3.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.3.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.3.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.3.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.3.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.3.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.3.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.3.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.3.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.3.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.3.output\n",
      "base_model.model.text_transformer.encoder.layer.3.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.3.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.3.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.4\n",
      "base_model.model.text_transformer.encoder.layer.4.attention\n",
      "base_model.model.text_transformer.encoder.layer.4.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.4.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.4.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.4.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.4.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.4.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.4.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.4.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.4.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.4.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.4.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.4.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.4.output\n",
      "base_model.model.text_transformer.encoder.layer.4.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.4.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.4.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.5\n",
      "base_model.model.text_transformer.encoder.layer.5.attention\n",
      "base_model.model.text_transformer.encoder.layer.5.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.5.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.5.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.5.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.5.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.5.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.5.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.5.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.5.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.5.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.5.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.5.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.5.output\n",
      "base_model.model.text_transformer.encoder.layer.5.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.5.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.5.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.6\n",
      "base_model.model.text_transformer.encoder.layer.6.attention\n",
      "base_model.model.text_transformer.encoder.layer.6.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.6.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.6.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.6.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.6.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.6.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.6.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.6.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.6.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.6.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.6.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.6.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.6.output\n",
      "base_model.model.text_transformer.encoder.layer.6.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.6.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.6.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.7\n",
      "base_model.model.text_transformer.encoder.layer.7.attention\n",
      "base_model.model.text_transformer.encoder.layer.7.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.7.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.7.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.7.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.7.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.7.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.7.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.7.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.7.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.7.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.7.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.7.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.7.output\n",
      "base_model.model.text_transformer.encoder.layer.7.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.7.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.7.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.8\n",
      "base_model.model.text_transformer.encoder.layer.8.attention\n",
      "base_model.model.text_transformer.encoder.layer.8.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.8.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.8.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.8.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.8.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.8.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.8.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.8.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.8.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.8.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.8.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.8.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.8.output\n",
      "base_model.model.text_transformer.encoder.layer.8.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.8.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.8.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.9\n",
      "base_model.model.text_transformer.encoder.layer.9.attention\n",
      "base_model.model.text_transformer.encoder.layer.9.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.9.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.9.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.9.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.9.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.9.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.9.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.9.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.9.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.9.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.9.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.9.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.9.output\n",
      "base_model.model.text_transformer.encoder.layer.9.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.9.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.9.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.10\n",
      "base_model.model.text_transformer.encoder.layer.10.attention\n",
      "base_model.model.text_transformer.encoder.layer.10.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.10.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.10.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.10.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.10.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.10.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.10.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.10.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.10.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.10.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.10.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.10.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.10.output\n",
      "base_model.model.text_transformer.encoder.layer.10.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.10.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.10.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.11\n",
      "base_model.model.text_transformer.encoder.layer.11.attention\n",
      "base_model.model.text_transformer.encoder.layer.11.attention.self\n",
      "base_model.model.text_transformer.encoder.layer.11.attention.self.query\n",
      "base_model.model.text_transformer.encoder.layer.11.attention.self.key\n",
      "base_model.model.text_transformer.encoder.layer.11.attention.self.value\n",
      "base_model.model.text_transformer.encoder.layer.11.attention.self.dropout\n",
      "base_model.model.text_transformer.encoder.layer.11.attention.output\n",
      "base_model.model.text_transformer.encoder.layer.11.attention.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.11.attention.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.11.attention.output.dropout\n",
      "base_model.model.text_transformer.encoder.layer.11.intermediate\n",
      "base_model.model.text_transformer.encoder.layer.11.intermediate.dense\n",
      "base_model.model.text_transformer.encoder.layer.11.intermediate.intermediate_act_fn\n",
      "base_model.model.text_transformer.encoder.layer.11.output\n",
      "base_model.model.text_transformer.encoder.layer.11.output.dense\n",
      "base_model.model.text_transformer.encoder.layer.11.output.LayerNorm\n",
      "base_model.model.text_transformer.encoder.layer.11.output.dropout\n",
      "base_model.model.text_transformer.pooler\n",
      "base_model.model.text_transformer.pooler.dense\n",
      "base_model.model.text_transformer.pooler.activation\n",
      "base_model.model.visual_transformer\n",
      "base_model.model.visual_transformer.spatial_rel_pos_bias\n",
      "base_model.model.visual_transformer.spatial_rel_pos_bias.net\n",
      "base_model.model.visual_transformer.spatial_rel_pos_bias.net.0\n",
      "base_model.model.visual_transformer.spatial_rel_pos_bias.net.0.0\n",
      "base_model.model.visual_transformer.spatial_rel_pos_bias.net.0.1\n",
      "base_model.model.visual_transformer.spatial_rel_pos_bias.net.1\n",
      "base_model.model.visual_transformer.spatial_rel_pos_bias.net.1.0\n",
      "base_model.model.visual_transformer.spatial_rel_pos_bias.net.1.1\n",
      "base_model.model.visual_transformer.spatial_rel_pos_bias.net.2\n",
      "base_model.model.visual_transformer.to_patch_emb_first_frame\n",
      "base_model.model.visual_transformer.to_patch_emb_first_frame.0\n",
      "base_model.model.visual_transformer.to_patch_emb_first_frame.1\n",
      "base_model.model.visual_transformer.to_patch_emb_first_frame.2\n",
      "base_model.model.visual_transformer.to_patch_emb_first_frame.3\n",
      "base_model.model.visual_transformer.to_patch_emb\n",
      "base_model.model.visual_transformer.to_patch_emb.0\n",
      "base_model.model.visual_transformer.to_patch_emb.1\n",
      "base_model.model.visual_transformer.to_patch_emb.2\n",
      "base_model.model.visual_transformer.to_patch_emb.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.0\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.0.dsconv\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.attn_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.norm\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.context_norm\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.base_layer\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_A.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_B.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_q.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.base_layer\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_A.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_B.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_kv.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.1.to_out\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.3.0\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.3.1\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.3.2\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.3.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.0.3.4\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.0\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.0.dsconv\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.attn_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.norm\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.context_norm\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.base_layer\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_A.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_B.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_q.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.base_layer\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_A.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_B.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_kv.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.1.to_out\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.3.0\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.3.1\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.3.2\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.3.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.1.3.4\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.0\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.0.dsconv\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.attn_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.norm\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.context_norm\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.base_layer\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_A.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_B.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_q.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.base_layer\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_A.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_B.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_kv.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.1.to_out\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.3.0\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.3.1\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.3.2\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.3.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.2.3.4\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.0\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.0.dsconv\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.attn_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.norm\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.context_norm\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.base_layer\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_A.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_B.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_q.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.base_layer\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_dropout\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_A.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_B.default\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_kv.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.1.to_out\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.3.0\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.3.1\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.3.2\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.3.3\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.layers.3.3.4\n",
      "base_model.model.visual_transformer.enc_spatial_transformer.norm_out\n",
      "base_model.model.visual_transformer.enc_temporal_transformer\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.0\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.0.dsconv\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.attn_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.norm\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.context_norm\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.base_layer\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_A.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_B.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_q.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.base_layer\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_A.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_B.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_kv.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.1.to_out\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.3\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.3.0\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.3.1\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.3.2\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.3.3\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.0.3.4\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.0\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.0.dsconv\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.attn_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.norm\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.context_norm\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.base_layer\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_A.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_B.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_q.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.base_layer\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_A.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_B.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_kv.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.1.to_out\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.3\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.3.0\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.3.1\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.3.2\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.3.3\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.1.3.4\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.0\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.0.dsconv\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.attn_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.norm\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.context_norm\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.base_layer\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_A.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_B.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_q.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.base_layer\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_A.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_B.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_kv.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.1.to_out\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.3\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.3.0\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.3.1\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.3.2\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.3.3\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.2.3.4\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.0\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.0.dsconv\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.attn_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.norm\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.context_norm\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.base_layer\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_A.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_B.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_q.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.base_layer\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_dropout\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_dropout.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_A.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_B.default\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_embedding_A\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_kv.lora_embedding_B\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.1.to_out\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.3\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.3.0\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.3.1\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.3.2\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.3.3\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.layers.3.3.4\n",
      "base_model.model.visual_transformer.enc_temporal_transformer.norm_out\n",
      "base_model.model.visual_transformer.vq\n",
      "base_model.model.visual_transformer.vq.project_in\n",
      "base_model.model.visual_transformer.vq.project_out\n",
      "base_model.model.visual_transformer.vq._codebook\n",
      "base_model.model.visual_transformer.to_pixels_first_frame\n",
      "base_model.model.visual_transformer.to_pixels_first_frame.0\n",
      "base_model.model.visual_transformer.to_pixels_first_frame.1\n",
      "base_model.model.visual_transformer.to_pixels\n",
      "base_model.model.visual_transformer.to_pixels.0\n",
      "base_model.model.visual_transformer.to_pixels.1\n",
      "base_model.model.to_text_latent\n",
      "base_model.model.to_visual_latent\n",
      "base_model.model.to_text_latent_extra\n",
      "base_model.model.to_visual_latent_extra\n"
     ]
    }
   ],
   "source": [
    "for name, module in clip.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "target =  [\"enc_spatial_transformer.layers.0.1.to_q\", \"enc_spatial_transformer.layers.0.1.to_kv\", \"enc_spatial_transformer.layers.0.1.to_out\",\n",
    "\"enc_spatial_transformer.layers.1.1.to_q\", \"enc_spatial_transformer.layers.1.1.to_kv\", \"enc_spatial_transformer.layers.1.1.to_out\",\n",
    "\"enc_spatial_transformer.layers.2.1.to_q\", \"enc_spatial_transformer.layers.2.1.to_kv\", \"enc_spatial_transformer.layers.2.1.to_out\",\n",
    "\"enc_spatial_transformer.layers.3.1.to_q\", \"enc_spatial_transformer.layers.3.1.to_kv\", \"enc_spatial_transformer.layers.3.1.to_out\",]\n",
    "peft_config = LoraConfig(\n",
    "    inference_mode=False, r=8, lora_alpha=64, lora_dropout=0.2, target_modules=target\n",
    ")\n",
    "\n",
    "clip = get_peft_model(clip, peft_config)\n",
    "\n",
    "output_file = \"new_lora.txt\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for name, module in clip.named_modules():\n",
    "        f.write(name + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clip\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clip' is not defined"
     ]
    }
   ],
   "source": [
    "clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/CT-CLIP/CT_CLIP/ct_clip/ct_clip.py:596: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt = torch.load(str(path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CTCLIP(\n",
       "  (text_transformer): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (visual_transformer): CTViT(\n",
       "    (spatial_rel_pos_bias): ContinuousPositionBias(\n",
       "      (net): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (2): Linear(in_features=512, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (to_patch_emb_first_frame): Sequential(\n",
       "      (0): Rearrange('b c 1 (h p1) (w p2) -> b 1 h w (c p1 p2)', p1=20, p2=20)\n",
       "      (1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Linear(in_features=400, out_features=512, bias=True)\n",
       "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (to_patch_emb): Sequential(\n",
       "      (0): Rearrange('b c (t pt) (h p1) (w p2) -> b t h w (c pt p1 p2)', p1=20, p2=20, pt=10)\n",
       "      (1): LayerNorm((4000,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Linear(in_features=4000, out_features=512, bias=True)\n",
       "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (enc_spatial_transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x ModuleList(\n",
       "          (0): PEG(\n",
       "            (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "            (context_norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "          )\n",
       "          (2): None\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "            (2): GEGLU()\n",
       "            (3): Dropout(p=0.0, inplace=False)\n",
       "            (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm()\n",
       "    )\n",
       "    (enc_temporal_transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x ModuleList(\n",
       "          (0): PEG(\n",
       "            (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "            (context_norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "          )\n",
       "          (2): None\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "            (2): GEGLU()\n",
       "            (3): Dropout(p=0.0, inplace=False)\n",
       "            (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm()\n",
       "    )\n",
       "    (vq): VectorQuantize(\n",
       "      (project_in): Identity()\n",
       "      (project_out): Identity()\n",
       "      (_codebook): CosineSimCodebook()\n",
       "    )\n",
       "    (to_pixels_first_frame): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=400, bias=True)\n",
       "      (1): Rearrange('b 1 h w (c p1 p2) -> b c 1 (h p1) (w p2)', p1=20, p2=20)\n",
       "    )\n",
       "    (to_pixels): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=4000, bias=True)\n",
       "      (1): Rearrange('b t h w (c pt p1 p2) -> b c (t pt) (h p1) (w p2)', p1=20, p2=20, pt=10)\n",
       "    )\n",
       "  )\n",
       "  (to_text_latent): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (to_visual_latent): Linear(in_features=294912, out_features=512, bias=False)\n",
       "  (to_text_latent_extra): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (to_visual_latent_extra): Linear(in_features=294912, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import Adam, AdamW\n",
    "from torchinfo import summary\n",
    "\n",
    "from utils import make_time_bins\n",
    "from utils import encode_survival, mtlr_neg_log_likelihood, make_optimizer\n",
    "from utils import mtlr_survival, mtlr_risk, roc_auc_at_times, brier_score_at_times\n",
    "from prognosis_model import model_lora, model_lora_again\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "\n",
    "\n",
    "from ct_clip import CTCLIP\n",
    "from transformer_maskgit import CTViT\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from lifelines.utils import concordance_index\n",
    "from data_inference_hector import Hector_Dataset_lora\n",
    "\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "num_time_bins = 12\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('microsoft/BiomedVLP-CXR-BERT-specialized',do_lower_case=True)\n",
    "text_encoder = BertModel.from_pretrained(\"microsoft/BiomedVLP-CXR-BERT-specialized\")\n",
    "\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "text_encoder.to(device)\n",
    "\n",
    "image_encoder = CTViT(\n",
    "    dim = 512,\n",
    "    codebook_size = 8192,\n",
    "    image_size = 480,\n",
    "    patch_size = 20,\n",
    "    temporal_patch_size = 10,\n",
    "    spatial_depth = 4,\n",
    "    temporal_depth = 4,\n",
    "    dim_head = 32,\n",
    "    heads = 8\n",
    ")\n",
    "\n",
    "image_encoder.to(device)\n",
    "\n",
    "clip = CTCLIP(\n",
    "    image_encoder = image_encoder,\n",
    "    text_encoder = text_encoder,\n",
    "    dim_image = 294912,\n",
    "    dim_text = 768,\n",
    "    dim_latent = 512,\n",
    "    extra_latent_projection = False,         # whether to use separate projections for text-to-image vs image-to-text comparisons (CLOOB)\n",
    "    use_mlm=False,\n",
    "    downsample_image_embeds = False,\n",
    "    use_all_token_embeds = False,\n",
    ")\n",
    "\n",
    "clip.load(\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/CT-CLIP_v2.pt\")\n",
    "clip.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_lora_again(\n",
       "  (clip): CTCLIP(\n",
       "    (text_transformer): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.25, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.25, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (visual_transformer): CTViT(\n",
       "      (spatial_rel_pos_bias): ContinuousPositionBias(\n",
       "        (net): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (2): Linear(in_features=512, out_features=8, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (to_patch_emb_first_frame): Sequential(\n",
       "        (0): Rearrange('b c 1 (h p1) (w p2) -> b 1 h w (c p1 p2)', p1=20, p2=20)\n",
       "        (1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): Linear(in_features=400, out_features=512, bias=True)\n",
       "        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (to_patch_emb): Sequential(\n",
       "        (0): Rearrange('b c (t pt) (h p1) (w p2) -> b t h w (c pt p1 p2)', p1=20, p2=20, pt=10)\n",
       "        (1): LayerNorm((4000,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): Linear(in_features=4000, out_features=512, bias=True)\n",
       "        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (enc_spatial_transformer): Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x ModuleList(\n",
       "            (0): PEG(\n",
       "              (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (norm): LayerNorm()\n",
       "              (context_norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "            )\n",
       "            (2): None\n",
       "            (3): Sequential(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "              (2): GEGLU()\n",
       "              (3): Dropout(p=0.0, inplace=False)\n",
       "              (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_out): LayerNorm()\n",
       "      )\n",
       "      (enc_temporal_transformer): Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x ModuleList(\n",
       "            (0): PEG(\n",
       "              (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (norm): LayerNorm()\n",
       "              (context_norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "            )\n",
       "            (2): None\n",
       "            (3): Sequential(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "              (2): GEGLU()\n",
       "              (3): Dropout(p=0.0, inplace=False)\n",
       "              (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_out): LayerNorm()\n",
       "      )\n",
       "      (vq): VectorQuantize(\n",
       "        (project_in): Identity()\n",
       "        (project_out): Identity()\n",
       "        (_codebook): CosineSimCodebook()\n",
       "      )\n",
       "      (to_pixels_first_frame): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=400, bias=True)\n",
       "        (1): Rearrange('b 1 h w (c p1 p2) -> b c 1 (h p1) (w p2)', p1=20, p2=20)\n",
       "      )\n",
       "      (to_pixels): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=4000, bias=True)\n",
       "        (1): Rearrange('b t h w (c pt p1 p2) -> b c (t pt) (h p1) (w p2)', p1=20, p2=20, pt=10)\n",
       "      )\n",
       "    )\n",
       "    (to_text_latent): Linear(in_features=768, out_features=512, bias=False)\n",
       "    (to_visual_latent): Linear(in_features=294912, out_features=512, bias=False)\n",
       "    (to_text_latent_extra): Linear(in_features=768, out_features=512, bias=False)\n",
       "    (to_visual_latent_extra): Linear(in_features=294912, out_features=512, bias=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (img_embd): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (text_embd): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fuse): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (mtlr): MTLR(in_features=128, num_time_bins=13)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peft_config = LoraConfig(\n",
    "#     inference_mode=False, r=8, lora_alpha=64, lora_dropout=0.2, target_modules=[\"to_q\", \"to_kv\"]\n",
    "# )\n",
    "\n",
    "# target =  [\"enc_spatial_transformer.layers.0.1.to_q\", \"enc_spatial_transformer.layers.0.1.to_kv\", \"enc_spatial_transformer.layers.0.1.to_out\",\n",
    "#     \"enc_spatial_transformer.layers.1.1.to_q\", \"enc_spatial_transformer.layers.1.1.to_kv\", \"enc_spatial_transformer.layers.1.1.to_out\",\n",
    "#     \"enc_spatial_transformer.layers.2.1.to_q\", \"enc_spatial_transformer.layers.2.1.to_kv\", \"enc_spatial_transformer.layers.2.1.to_out\",\n",
    "#     \"enc_spatial_transformer.layers.3.1.to_q\", \"enc_spatial_transformer.layers.3.1.to_kv\", \"enc_spatial_transformer.layers.3.1.to_out\",]\n",
    "\n",
    "target = [\"to_q\", \"to_kv\"]    \n",
    "peft_config = LoraConfig(\n",
    "    inference_mode=False, r=2, lora_alpha=32, lora_dropout=0.2, target_modules=target, \n",
    "    # task_type='QUESTION_ANS'\n",
    ")\n",
    "\n",
    "model_ = model_lora_again(clip, device, peft_config, num_time_bins)\n",
    "model_.to(device)\n",
    "\n",
    "# from peft import get_peft_model\n",
    "\n",
    "# model = get_peft_model(model_, peft_config)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_inference_hector import Hector_Dataset_lora\n",
    "\n",
    "df = pd.read_csv(\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/TNM_hector_prompts.csv\")\n",
    "\n",
    "hect_dataset = Hector_Dataset_lora(data_folder = \"/share/sda/mohammadqazi/project/hector/pre_processed/\",  \n",
    "            csv_file =\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/TNM_hector_prompts.csv\")\n",
    "\n",
    "train_dataset, test_dataset = hect_dataset.train_val_split(fold=0)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "time_bins = make_time_bins(df['RFS'].values, event=df['Relapse'].values, num_bins=num_time_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================\n",
       "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #\n",
       "=======================================================================================================================================\n",
       "model_lora_again                                             [4, 1, 240, 480, 480]     [4, 13]                   --\n",
       "├─CTCLIP: 1-1                                                --                        [4, 24, 24, 512]          302,776,321\n",
       "│    └─BertModel: 2-1                                        [4, 512]                  [4, 768]                  --\n",
       "│    │    └─BertEmbeddings: 3-1                              --                        [4, 512, 768]             --\n",
       "│    │    │    └─Embedding: 4-1                              [4, 512]                  [4, 512, 768]             23,440,896\n",
       "│    │    │    └─Embedding: 4-2                              [4, 512]                  [4, 512, 768]             1,536\n",
       "│    │    │    └─Embedding: 4-3                              [1, 512]                  [1, 512, 768]             393,216\n",
       "│    │    │    └─LayerNorm: 4-4                              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    └─Dropout: 4-5                                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    └─BertEncoder: 3-2                                 [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    └─ModuleList: 4-6                             --                        --                        --\n",
       "│    │    │    │    └─BertLayer: 5-1                         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-1                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-1       [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-1             [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-2             [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-3             [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-4            [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-2          [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-5             [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-6            [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-7          [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-2             [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-3                  [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-4          [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-3                   [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-5                  [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-6                 [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-7               [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-2                         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-4                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-8       [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-8             [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-9             [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-10            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-11           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-9          [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-12            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-13           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-14         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-5             [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-10                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-11         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-6                   [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-12                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-13                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-14              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-3                         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-7                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-15      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-15            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-16            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-17            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-18           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-16         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-19            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-20           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-21         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-8             [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-17                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-18         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-9                   [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-19                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-20                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-21              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-4                         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-10               [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-22      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-22            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-23            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-24            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-25           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-23         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-26            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-27           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-28         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-11            [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-24                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-25         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-12                  [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-26                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-27                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-28              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-5                         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-13               [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-29      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-29            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-30            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-31            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-32           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-30         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-33            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-34           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-35         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-14            [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-31                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-32         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-15                  [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-33                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-34                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-35              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-6                         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-16               [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-36      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-36            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-37            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-38            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-39           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-37         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-40            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-41           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-42         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-17            [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-38                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-39         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-18                  [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-40                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-41                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-42              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-7                         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-19               [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-43      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-43            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-44            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-45            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-46           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-44         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-47            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-48           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-49         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-20            [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-45                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-46         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-21                  [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-47                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-48                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-49              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-8                         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-22               [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-50      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-50            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-51            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-52            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-53           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-51         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-54            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-55           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-56         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-23            [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-52                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-53         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-24                  [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-54                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-55                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-56              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-9                         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-25               [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-57      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-57            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-58            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-59            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-60           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-58         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-61            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-62           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-63         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-26            [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-59                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-60         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-27                  [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-61                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-62                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-63              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-10                        [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-28               [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-64      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-64            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-65            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-66            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-67           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-65         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-68            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-69           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-70         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-29            [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-66                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-67         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-30                  [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-68                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-69                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-70              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-11                        [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-31               [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-71      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-71            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-72            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-73            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-74           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-72         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-75            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-76           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-77         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-32            [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-73                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-74         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-33                  [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-75                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-76                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-77              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    └─BertLayer: 5-12                        [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    └─BertAttention: 6-34               [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-78      [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-78            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-79            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Linear: 8-80            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-81           [4, 12, 512, 512]         [4, 12, 512, 512]         --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-79         [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─Linear: 8-82            [4, 512, 768]             [4, 512, 768]             590,592\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-83           [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-84         [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    │    │    │    └─BertIntermediate: 6-35            [4, 512, 768]             [4, 512, 3072]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-80                 [4, 512, 768]             [4, 512, 3072]            2,362,368\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-81         [4, 512, 3072]            [4, 512, 3072]            --\n",
       "│    │    │    │    │    └─BertOutput: 6-36                  [4, 512, 3072]            [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─Linear: 7-82                 [4, 512, 3072]            [4, 512, 768]             2,360,064\n",
       "│    │    │    │    │    │    └─Dropout: 7-83                [4, 512, 768]             [4, 512, 768]             --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-84              [4, 512, 768]             [4, 512, 768]             1,536\n",
       "│    │    └─BertPooler: 3-3                                  [4, 512, 768]             [4, 768]                  --\n",
       "│    │    │    └─Linear: 4-7                                 [4, 768]                  [4, 768]                  590,592\n",
       "│    │    │    └─Tanh: 4-8                                   [4, 768]                  [4, 768]                  --\n",
       "│    └─CTViT: 2-2                                            [4, 1, 240, 480, 480]     [4, 24, 24, 24, 512]      13,014,352\n",
       "│    │    └─Sequential: 3-4                                  [4, 1, 240, 480, 480]     [4, 24, 24, 24, 512]      --\n",
       "│    │    │    └─Rearrange: 4-9                              [4, 1, 240, 480, 480]     [4, 24, 24, 24, 4000]     --\n",
       "│    │    │    └─LayerNorm: 4-10                             [4, 24, 24, 24, 4000]     [4, 24, 24, 24, 4000]     8,000\n",
       "│    │    │    └─Linear: 4-11                                [4, 24, 24, 24, 4000]     [4, 24, 24, 24, 512]      2,048,512\n",
       "│    │    │    └─LayerNorm: 4-12                             [4, 24, 24, 24, 512]      [4, 24, 24, 24, 512]      1,024\n",
       "│    │    └─ContinuousPositionBias: 3-5                      --                        [8, 576, 576]             --\n",
       "│    │    │    └─ModuleList: 4-13                            --                        --                        --\n",
       "│    │    │    │    └─Sequential: 5-13                       [576, 576, 2]             [576, 576, 512]           --\n",
       "│    │    │    │    │    └─Linear: 6-37                      [576, 576, 2]             [576, 576, 512]           1,536\n",
       "│    │    │    │    │    └─LeakyReLU: 6-38                   [576, 576, 512]           [576, 576, 512]           --\n",
       "│    │    │    │    └─Sequential: 5-14                       [576, 576, 512]           [576, 576, 512]           --\n",
       "│    │    │    │    │    └─Linear: 6-39                      [576, 576, 512]           [576, 576, 512]           262,656\n",
       "│    │    │    │    │    └─LeakyReLU: 6-40                   [576, 576, 512]           [576, 576, 512]           --\n",
       "│    │    │    │    └─Linear: 5-15                           [576, 576, 512]           [576, 576, 8]             4,104\n",
       "│    │    └─Transformer: 3-6                                 [96, 576, 512]            [96, 576, 512]            --\n",
       "│    │    │    └─ModuleList: 4-14                            --                        --                        --\n",
       "│    │    │    │    └─ModuleList: 5-16                       --                        --                        --\n",
       "│    │    │    │    │    └─PEG: 6-41                         [96, 576, 512]            [96, 576, 512]            --\n",
       "│    │    │    │    │    │    └─Conv3d: 7-85                 [4, 512, 26, 26, 26]      [4, 512, 24, 24, 24]      14,336\n",
       "│    │    │    │    │    └─Attention: 6-42                   [96, 576, 512]            [96, 576, 512]            576\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-86              [96, 576, 512]            [96, 576, 512]            512\n",
       "│    │    │    │    │    │    └─Linear: 7-87                 [96, 576, 512]            [96, 576, 256]            131,072\n",
       "│    │    │    │    │    │    └─Linear: 7-88                 [96, 576, 512]            [96, 576, 512]            262,144\n",
       "│    │    │    │    │    │    └─Dropout: 7-89                [96, 8, 576, 576]         [96, 8, 576, 576]         --\n",
       "│    │    │    │    │    │    └─Linear: 7-90                 [96, 576, 256]            [96, 576, 512]            131,072\n",
       "│    │    │    │    │    └─Sequential: 6-43                  [96, 576, 512]            [96, 576, 512]            --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-91              [96, 576, 512]            [96, 576, 512]            1,024\n",
       "│    │    │    │    │    │    └─Linear: 7-92                 [96, 576, 512]            [96, 576, 2730]           1,397,760\n",
       "│    │    │    │    │    │    └─GEGLU: 7-93                  [96, 576, 2730]           [96, 576, 1365]           --\n",
       "│    │    │    │    │    │    └─Dropout: 7-94                [96, 576, 1365]           [96, 576, 1365]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-95                 [96, 576, 1365]           [96, 576, 512]            698,880\n",
       "│    │    │    │    └─ModuleList: 5-17                       --                        --                        --\n",
       "│    │    │    │    │    └─PEG: 6-44                         [96, 576, 512]            [96, 576, 512]            --\n",
       "│    │    │    │    │    │    └─Conv3d: 7-96                 [4, 512, 26, 26, 26]      [4, 512, 24, 24, 24]      14,336\n",
       "│    │    │    │    │    └─Attention: 6-45                   [96, 576, 512]            [96, 576, 512]            576\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-97              [96, 576, 512]            [96, 576, 512]            512\n",
       "│    │    │    │    │    │    └─Linear: 7-98                 [96, 576, 512]            [96, 576, 256]            131,072\n",
       "│    │    │    │    │    │    └─Linear: 7-99                 [96, 576, 512]            [96, 576, 512]            262,144\n",
       "│    │    │    │    │    │    └─Dropout: 7-100               [96, 8, 576, 576]         [96, 8, 576, 576]         --\n",
       "│    │    │    │    │    │    └─Linear: 7-101                [96, 576, 256]            [96, 576, 512]            131,072\n",
       "│    │    │    │    │    └─Sequential: 6-46                  [96, 576, 512]            [96, 576, 512]            --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-102             [96, 576, 512]            [96, 576, 512]            1,024\n",
       "│    │    │    │    │    │    └─Linear: 7-103                [96, 576, 512]            [96, 576, 2730]           1,397,760\n",
       "│    │    │    │    │    │    └─GEGLU: 7-104                 [96, 576, 2730]           [96, 576, 1365]           --\n",
       "│    │    │    │    │    │    └─Dropout: 7-105               [96, 576, 1365]           [96, 576, 1365]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-106                [96, 576, 1365]           [96, 576, 512]            698,880\n",
       "│    │    │    │    └─ModuleList: 5-18                       --                        --                        --\n",
       "│    │    │    │    │    └─PEG: 6-47                         [96, 576, 512]            [96, 576, 512]            --\n",
       "│    │    │    │    │    │    └─Conv3d: 7-107                [4, 512, 26, 26, 26]      [4, 512, 24, 24, 24]      14,336\n",
       "│    │    │    │    │    └─Attention: 6-48                   [96, 576, 512]            [96, 576, 512]            576\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-108             [96, 576, 512]            [96, 576, 512]            512\n",
       "│    │    │    │    │    │    └─Linear: 7-109                [96, 576, 512]            [96, 576, 256]            131,072\n",
       "│    │    │    │    │    │    └─Linear: 7-110                [96, 576, 512]            [96, 576, 512]            262,144\n",
       "│    │    │    │    │    │    └─Dropout: 7-111               [96, 8, 576, 576]         [96, 8, 576, 576]         --\n",
       "│    │    │    │    │    │    └─Linear: 7-112                [96, 576, 256]            [96, 576, 512]            131,072\n",
       "│    │    │    │    │    └─Sequential: 6-49                  [96, 576, 512]            [96, 576, 512]            --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-113             [96, 576, 512]            [96, 576, 512]            1,024\n",
       "│    │    │    │    │    │    └─Linear: 7-114                [96, 576, 512]            [96, 576, 2730]           1,397,760\n",
       "│    │    │    │    │    │    └─GEGLU: 7-115                 [96, 576, 2730]           [96, 576, 1365]           --\n",
       "│    │    │    │    │    │    └─Dropout: 7-116               [96, 576, 1365]           [96, 576, 1365]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-117                [96, 576, 1365]           [96, 576, 512]            698,880\n",
       "│    │    │    │    └─ModuleList: 5-19                       --                        --                        --\n",
       "│    │    │    │    │    └─PEG: 6-50                         [96, 576, 512]            [96, 576, 512]            --\n",
       "│    │    │    │    │    │    └─Conv3d: 7-118                [4, 512, 26, 26, 26]      [4, 512, 24, 24, 24]      14,336\n",
       "│    │    │    │    │    └─Attention: 6-51                   [96, 576, 512]            [96, 576, 512]            576\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-119             [96, 576, 512]            [96, 576, 512]            512\n",
       "│    │    │    │    │    │    └─Linear: 7-120                [96, 576, 512]            [96, 576, 256]            131,072\n",
       "│    │    │    │    │    │    └─Linear: 7-121                [96, 576, 512]            [96, 576, 512]            262,144\n",
       "│    │    │    │    │    │    └─Dropout: 7-122               [96, 8, 576, 576]         [96, 8, 576, 576]         --\n",
       "│    │    │    │    │    │    └─Linear: 7-123                [96, 576, 256]            [96, 576, 512]            131,072\n",
       "│    │    │    │    │    └─Sequential: 6-52                  [96, 576, 512]            [96, 576, 512]            --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-124             [96, 576, 512]            [96, 576, 512]            1,024\n",
       "│    │    │    │    │    │    └─Linear: 7-125                [96, 576, 512]            [96, 576, 2730]           1,397,760\n",
       "│    │    │    │    │    │    └─GEGLU: 7-126                 [96, 576, 2730]           [96, 576, 1365]           --\n",
       "│    │    │    │    │    │    └─Dropout: 7-127               [96, 576, 1365]           [96, 576, 1365]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-128                [96, 576, 1365]           [96, 576, 512]            698,880\n",
       "│    │    │    └─LayerNorm: 4-15                             [96, 576, 512]            [96, 576, 512]            512\n",
       "├─AdaptiveAvgPool2d: 1-2                                     [4, 512, 24, 24]          [4, 512, 1, 1]            --\n",
       "├─Sequential: 1-3                                            [4, 512]                  [4, 512]                  --\n",
       "│    └─Linear: 2-3                                           [4, 512]                  [4, 512]                  262,656\n",
       "│    └─GELU: 2-4                                             [4, 512]                  [4, 512]                  --\n",
       "│    └─Linear: 2-5                                           [4, 512]                  [4, 512]                  262,656\n",
       "│    └─LayerNorm: 2-6                                        [4, 512]                  [4, 512]                  1,024\n",
       "├─Sequential: 1-4                                            [4, 768]                  [4, 512]                  --\n",
       "│    └─Linear: 2-7                                           [4, 768]                  [4, 512]                  393,728\n",
       "│    └─GELU: 2-8                                             [4, 512]                  [4, 512]                  --\n",
       "│    └─Linear: 2-9                                           [4, 512]                  [4, 512]                  262,656\n",
       "│    └─LayerNorm: 2-10                                       [4, 512]                  [4, 512]                  1,024\n",
       "├─Sequential: 1-5                                            [4, 1024]                 [4, 128]                  --\n",
       "│    └─Linear: 2-11                                          [4, 1024]                 [4, 512]                  524,800\n",
       "│    └─ReLU: 2-12                                            [4, 512]                  [4, 512]                  --\n",
       "│    └─Linear: 2-13                                          [4, 512]                  [4, 128]                  65,664\n",
       "├─MTLR: 1-6                                                  [4, 128]                  [4, 13]                   1,548\n",
       "=======================================================================================================================================\n",
       "Total params: 439,924,517\n",
       "Trainable params: 439,924,517\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.78\n",
       "=======================================================================================================================================\n",
       "Input size (MB): 884.79\n",
       "Forward/backward pass size (MB): 17609.54\n",
       "Params size (MB): 496.53\n",
       "Estimated Total Size (MB): 18990.85\n",
       "======================================================================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_emb, text_emb, relapse, RFS, _, _ = next(iter(train_loader))\n",
    "img_emb = img_emb.to(device)\n",
    "text_tokens=tokenizer(text_emb, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512).to(device)\n",
    "y = encode_survival(RFS, relapse, time_bins).to(device)\n",
    "relapse = relapse.to(device)\n",
    "RFS = RFS.to(device)\n",
    "summary(model_, input_data=[img_emb, text_tokens ], depth=8, col_names=[\"input_size\", \"output_size\", \"num_params\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 439,953,189\n",
      "Trainable Parameters (LoRA applied): 28,672\n",
      "trainable params: 28,672 || all params: 439,953,189 || trainable%: 0.006517056977168542\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters (LoRA applied): {trainable_params:,}\")\n",
    "\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Expected 13824 tokens, but got 575.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 182\u001b[0m\n\u001b[1;32m    179\u001b[0m net \u001b[39m=\u001b[39m MyUNETR3D(hidden_size\u001b[39m=\u001b[39mC, feat_size\u001b[39m=\u001b[39m(D, H, W), base_channels\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, out_channels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[39m# Forward pass:\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m seg_logits \u001b[39m=\u001b[39m net(enc_image, hs_list)\n\u001b[1;32m    183\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSegmentation output shape:\u001b[39m\u001b[39m\"\u001b[39m, seg_logits\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    184\u001b[0m \u001b[39m# For example, you might expect an output of shape [B, out_channels, (upsampled D), (upsampled H), (upsampled W)]\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 132\u001b[0m, in \u001b[0;36mMyUNETR3D.forward\u001b[0;34m(self, enc_image, hidden_states)\u001b[0m\n\u001b[1;32m    124\u001b[0m x_main \u001b[39m=\u001b[39m enc_image\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()  \u001b[39m# [B, C, D, H, W]\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m# --- Prepare skip connections ---\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m# Remove the first token (assumed to be a [CLS] token) and project the rest into a 3D feature map.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# Here we assume that:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m#   - hidden_states[9] is used as the deepest skip connection,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m#   - hidden_states[6] as the intermediate,\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m#   - hidden_states[3] as the shallow one.\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m skip_deep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproj_feat(hidden_states[\u001b[39m9\u001b[39;49m][:, \u001b[39m1\u001b[39;49m:, :])  \u001b[39m# shape: [B, hidden_size, D, H, W]\u001b[39;00m\n\u001b[1;32m    133\u001b[0m skip_mid  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_feat(hidden_states[\u001b[39m6\u001b[39m][:, \u001b[39m1\u001b[39m:, :])\n\u001b[1;32m    134\u001b[0m skip_shallow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_feat(hidden_states[\u001b[39m3\u001b[39m][:, \u001b[39m1\u001b[39m:, :])\n",
      "Cell \u001b[0;32mIn[2], line 104\u001b[0m, in \u001b[0;36mMyUNETR3D.proj_feat\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m B, num_tokens, C \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[1;32m    103\u001b[0m D, H, W \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeat_size\n\u001b[0;32m--> 104\u001b[0m \u001b[39massert\u001b[39;00m num_tokens \u001b[39m==\u001b[39m D \u001b[39m*\u001b[39m H \u001b[39m*\u001b[39m W, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m{\u001b[39;00mD\u001b[39m*\u001b[39mH\u001b[39m*\u001b[39mW\u001b[39m}\u001b[39;00m\u001b[39m tokens, but got \u001b[39m\u001b[39m{\u001b[39;00mnum_tokens\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(B, D, H, W, C)      \u001b[39m# [B, D, H, W, C]\u001b[39;00m\n\u001b[1;32m    106\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()  \u001b[39m# [B, C, D, H, W]\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Expected 13824 tokens, but got 575."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "###############################################################################\n",
    "# A helper block that upsamples a feature map and fuses it with a skip connection.\n",
    "# Here we simply upsample with a ConvTranspose3d, concatenate the skip feature,\n",
    "# then apply a convolution + BN + ReLU.\n",
    "###############################################################################\n",
    "class DecoderBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels, \n",
    "                 up_kernel_size=2, conv_kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose3d(in_channels, out_channels, \n",
    "                                           kernel_size=up_kernel_size, stride=up_kernel_size)\n",
    "        # We use concatenation so the channel dimension is (upsampled + skip)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(out_channels + skip_channels, out_channels, \n",
    "                      kernel_size=conv_kernel_size, padding=conv_kernel_size // 2),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        # Make sure that x and skip have the same spatial dimensions;\n",
    "        # if not, you might need to crop or interpolate.\n",
    "        if skip is not None:\n",
    "            # Concatenate along the channel dimension\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "###############################################################################\n",
    "# A simple output block that maps the final features to segmentation classes.\n",
    "###############################################################################\n",
    "class UnetOutBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "###############################################################################\n",
    "# The main network that mimics a UNETR‐style design.\n",
    "#\n",
    "# - The main feature comes from the visual transformer as \"enc_image\" (which is\n",
    "#   a 5D tensor: [B, D, H, W, C]). We first permute it to [B, C, D, H, W].\n",
    "#\n",
    "# - Three skip connections are taken from transformer hidden states.\n",
    "#   (We assume that each hidden state is originally of shape [B, num_tokens+1, C],\n",
    "#    with the first token being a [CLS] token that we remove.)\n",
    "#\n",
    "# - The helper method `proj_feat` reshapes a hidden state token sequence of shape\n",
    "#   [B, num_tokens, C] into a spatial map of shape [B, C, D, H, W], where D×H×W\n",
    "#   is provided via the attribute `feat_size`.\n",
    "###############################################################################\n",
    "class MyUNETR3D(nn.Module):\n",
    "    def __init__(self, hidden_size=512, \n",
    "                 feat_size=(24, 24, 24),  # spatial grid dimensions for the hidden tokens\n",
    "                 base_channels=64,      # base number of channels in the decoder\n",
    "                 out_channels=2         # number of segmentation classes\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.feat_size = feat_size  # for example, if the transformer produces 24*24*24 tokens\n",
    "        # In our design we assume that both the main branch and each skip connection\n",
    "        # have \"hidden_size\" channels.\n",
    "        #\n",
    "        # We'll define three decoder blocks:\n",
    "        #  - First decoder block: upsamples from the main feature (enc_image) and fuses with the deepest skip.\n",
    "        #  - Second decoder block: fuses with a mid-level skip.\n",
    "        #  - Third decoder block: fuses with the shallow skip.\n",
    "        #\n",
    "        # Then an extra upsampling + conv brings us to the desired segmentation resolution.\n",
    "        self.dec_block1 = DecoderBlock3D(in_channels=hidden_size, \n",
    "                                         skip_channels=hidden_size, \n",
    "                                         out_channels=base_channels * 4)\n",
    "        self.dec_block2 = DecoderBlock3D(in_channels=base_channels * 4, \n",
    "                                         skip_channels=hidden_size, \n",
    "                                         out_channels=base_channels * 2)\n",
    "        self.dec_block3 = DecoderBlock3D(in_channels=base_channels * 2, \n",
    "                                         skip_channels=hidden_size, \n",
    "                                         out_channels=base_channels)\n",
    "        # One more upsampling (without skip connection) to reach a higher spatial resolution:\n",
    "        self.up_conv = nn.ConvTranspose3d(base_channels, base_channels, kernel_size=2, stride=2)\n",
    "        self.out_block = UnetOutBlock3D(base_channels, out_channels)\n",
    "    \n",
    "    def proj_feat(self, x):\n",
    "        \"\"\"\n",
    "        Projects a transformer hidden state (after removing any [CLS] token) into\n",
    "        a 3D spatial feature map.\n",
    "        \n",
    "        Args:\n",
    "            x: Tensor of shape [B, num_tokens, hidden_size]. Here num_tokens must equal\n",
    "               feat_size[0] * feat_size[1] * feat_size[2].\n",
    "        \n",
    "        Returns:\n",
    "            A tensor of shape [B, hidden_size, D, H, W].\n",
    "        \"\"\"\n",
    "        B, num_tokens, C = x.shape\n",
    "        D, H, W = self.feat_size\n",
    "        assert num_tokens == D * H * W, f\"Expected {D*H*W} tokens, but got {num_tokens}.\"\n",
    "        x = x.view(B, D, H, W, C)      # [B, D, H, W, C]\n",
    "        x = x.permute(0, 4, 1, 2, 3).contiguous()  # [B, C, D, H, W]\n",
    "        return x\n",
    "    \n",
    "    def forward(self, enc_image, hidden_states):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enc_image: The spatial feature from the visual transformer.\n",
    "                       Expected shape: [B, D, H, W, C]  (e.g., [4, 24, 24, 24, 512])\n",
    "            hidden_states: A list of transformer hidden states to be used as skip connections.\n",
    "                           Each element is expected to be of shape [B, num_tokens+1, C]\n",
    "                           (the first token is assumed to be a classification token that will be dropped).\n",
    "                           For example, use hidden_states[9], hidden_states[6], hidden_states[3].\n",
    "        \n",
    "        Returns:\n",
    "            seg_out: The segmentation logits.\n",
    "        \"\"\"\n",
    "        # --- Main branch ---\n",
    "        # Permute enc_image to get channels-first:\n",
    "        x_main = enc_image.permute(0, 4, 1, 2, 3).contiguous()  # [B, C, D, H, W]\n",
    "        \n",
    "        # --- Prepare skip connections ---\n",
    "        # Remove the first token (assumed to be a [CLS] token) and project the rest into a 3D feature map.\n",
    "        # Here we assume that:\n",
    "        #   - hidden_states[9] is used as the deepest skip connection,\n",
    "        #   - hidden_states[6] as the intermediate,\n",
    "        #   - hidden_states[3] as the shallow one.\n",
    "        skip_deep = self.proj_feat(hidden_states[9][:, 1:, :])  # shape: [B, hidden_size, D, H, W]\n",
    "        skip_mid  = self.proj_feat(hidden_states[6][:, 1:, :])\n",
    "        skip_shallow = self.proj_feat(hidden_states[3][:, 1:, :])\n",
    "        \n",
    "        # --- Decoder: fuse the main feature with the skip connections ---\n",
    "        x = self.dec_block1(x_main, skip_deep)\n",
    "        x = self.dec_block2(x, skip_mid)\n",
    "        x = self.dec_block3(x, skip_shallow)\n",
    "        \n",
    "        # Optionally, upsample once more to get a higher resolution segmentation map.\n",
    "        x = self.up_conv(x)\n",
    "        seg_out = self.out_block(x)\n",
    "        return seg_out\n",
    "\n",
    "###############################################################################\n",
    "# Example usage:\n",
    "#\n",
    "# Suppose that your visual transformer returns:\n",
    "#  - enc_image: a tensor of shape [B, 24, 24, 24, 512]\n",
    "#  - hidden_states: a list (with at least indices 3, 6, 9) where each element is of shape\n",
    "#    [B, num_tokens+1, 512]. For example, if the tokens form a 3D grid of 24x24x24,\n",
    "#    then num_tokens == 24*24*24.\n",
    "###############################################################################\n",
    "if __name__ == '__main__':\n",
    "    # Create dummy inputs:\n",
    "    B = 4\n",
    "    D = H = W = 24\n",
    "    C = 512\n",
    "    num_tokens = D * H * W  # 24*24*24 = 13824 tokens\n",
    "    \n",
    "    # Dummy enc_image: already spatial, shape [B, D, H, W, C]\n",
    "    enc_image = torch.randn(B, D, H, W, C)\n",
    "    \n",
    "    # Create dummy hidden states.\n",
    "    # For each skip connection we simulate a tensor with an extra [CLS] token.\n",
    "    # For simplicity, we use the same spatial resolution here.\n",
    "    dummy_hidden_state = torch.randn(B, 576, C)\n",
    "    # Build a list for indices 3, 6, 9 (the values don’t matter here)\n",
    "    hidden_states = {3: dummy_hidden_state, 6: dummy_hidden_state, 9: dummy_hidden_state}\n",
    "    # For convenience, we put them in a list where index corresponds to the transformer layer index.\n",
    "    # In practice your transformer might return a list; here we just construct one.\n",
    "    hs_list = [None] * 10\n",
    "    hs_list[3] = hidden_states[3]\n",
    "    hs_list[6] = hidden_states[6]\n",
    "    hs_list[9] = hidden_states[9]\n",
    "    \n",
    "    # Initialize the network\n",
    "    net = MyUNETR3D(hidden_size=C, feat_size=(D, H, W), base_channels=64, out_channels=2)\n",
    "    \n",
    "    # Forward pass:\n",
    "    seg_logits = net(enc_image, hs_list)\n",
    "    print(\"Segmentation output shape:\", seg_logits.shape)\n",
    "    # For example, you might expect an output of shape [B, out_channels, (upsampled D), (upsampled H), (upsampled W)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnetrBasicBlock(\n",
       "  (layer): UnetResBlock(\n",
       "    (conv1): Convolution(\n",
       "      (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (conv2): Convolution(\n",
       "      (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (conv3): Convolution(\n",
       "      (conv): Conv3d(1, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (norm3): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from monai.networks.blocks.unetr_block import UnetrBasicBlock, UnetrPrUpBlock, UnetrUpBlock\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder1 = UnetrBasicBlock(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=16,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    norm_name='instance',\n",
    "    res_block=True,\n",
    ")\n",
    "encoder1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 1, 240, 480, 480])\n",
      "Output shape: torch.Size([1, 16, 240, 480, 480])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.networks.blocks.unetr_block import UnetrBasicBlock\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder1 = UnetrBasicBlock(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=16,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    ")\n",
    "encoder1.to(device)\n",
    "\n",
    "# Create a dummy input with shape (batch_size, 1, 240, 480, 480)\n",
    "dummy_input = torch.randn(1, 1, 240, 480, 480).to(device)  # batch_size = 2\n",
    "\n",
    "# Forward the dummy input through the block.\n",
    "output = encoder1(dummy_input)\n",
    "\n",
    "print(\"Input shape: \", dummy_input.shape)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 24, 24, 24])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def proj_feat(x, hidden_size, feat_size):\n",
    "    new_view = (x.size(0), *feat_size, hidden_size)\n",
    "    x = x.view(new_view)\n",
    "    new_axes = (0, len(x.shape) - 1) + tuple(d + 1 for d in range(len(feat_size)))\n",
    "    x = x.permute(new_axes).contiguous()\n",
    "    return x\n",
    "\n",
    "dummy_input = torch.randn(4, 13824, 512).to(device)  # batch_size = 2\n",
    "proj_feat(dummy_input[:,:,:], 512, (24, 24, 24)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([4, 512, 24, 24, 24])\n",
      "Output shape: torch.Size([4, 32, 192, 192, 192])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.networks.blocks.unetr_block import UnetrPrUpBlock, UnetrUpBlock\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder2 = UnetrPrUpBlock(\n",
    "    spatial_dims=3,\n",
    "    in_channels=512,\n",
    "    out_channels=16 * 2,\n",
    "    num_layer=2,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    upsample_kernel_size=2,\n",
    "    norm_name='instance',\n",
    "    conv_block=True,\n",
    "    res_block=True,\n",
    ")\n",
    "encoder2.to(device)\n",
    "\n",
    "# Create a dummy input with shape (batch_size, 1, 240, 480, 480)\n",
    "dummy_input = torch.randn(4, 512, 24, 24, 24).to(device)  # batch_size = 2\n",
    "print(\"Input shape: \", dummy_input.shape)\n",
    "\n",
    "# Forward the dummy input through the block.\n",
    "output = encoder2(dummy_input)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 512, 24, 24, 24])\n",
      "Output shape: torch.Size([1, 64, 192, 192, 192])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.networks.blocks.unetr_block import UnetrPrUpBlock, UnetrUpBlock\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder3 = UnetrPrUpBlock(\n",
    "    spatial_dims=3,\n",
    "    in_channels=512,\n",
    "    out_channels=16 * 4,\n",
    "    num_layer=2,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    upsample_kernel_size=2,\n",
    "    norm_name='instance',\n",
    "    conv_block=True,\n",
    "    res_block=True,\n",
    ")\n",
    "encoder3.to(device)\n",
    "\n",
    "# Create a dummy input with shape (batch_size, 1, 240, 480, 480)\n",
    "dummy_input = torch.randn(1, 512, 24, 24, 24).to(device)  # batch_size = 2\n",
    "print(\"Input shape: \", dummy_input.shape)\n",
    "\n",
    "# Forward the dummy input through the block.\n",
    "output = encoder3(dummy_input)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 512, 24, 24, 24])\n",
      "Output shape: torch.Size([1, 128, 192, 192, 192])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.networks.blocks.unetr_block import UnetrPrUpBlock, UnetrUpBlock\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder4 = UnetrPrUpBlock(\n",
    "    spatial_dims=3,\n",
    "    in_channels=512,\n",
    "    out_channels=16 * 8,\n",
    "    num_layer=2,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    upsample_kernel_size=2,\n",
    "    norm_name='instance',\n",
    "    conv_block=True,\n",
    "    res_block=True,\n",
    ")\n",
    "encoder4.to(device)\n",
    "\n",
    "# Create a dummy input with shape (batch_size, 1, 240, 480, 480)\n",
    "dummy_input = torch.randn(1, 512, 24, 24, 24).to(device)  # batch_size = 2\n",
    "print(\"Input shape: \", dummy_input.shape)\n",
    "\n",
    "# Forward the dummy input through the block.\n",
    "output = encoder4(dummy_input)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 576, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct_clip.ct_clip_seg import seg_model\n",
    "model = seg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seg_model(\n",
       "  (encoder1): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(512, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(512, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder2): UnetrPrUpBlock(\n",
       "    (transp_conv_init): Convolution(\n",
       "      (conv): ConvTranspose3d(512, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): ConvTranspose3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder3): UnetrPrUpBlock(\n",
       "    (transp_conv_init): Convolution(\n",
       "      (conv): ConvTranspose3d(512, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): ConvTranspose3d(64, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder4): UnetrPrUpBlock(\n",
       "    (transp_conv_init): Convolution(\n",
       "      (conv): ConvTranspose3d(512, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList()\n",
       "  )\n",
       "  (decoder5): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(512, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(32, 16, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (out): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 512, 3, 3, 3], expected input[1, 1, 240, 480, 480] to have 512 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m240\u001b[39;49m, \u001b[39m480\u001b[39;49m, \u001b[39m480\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device), [torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m, \u001b[39m13824\u001b[39;49m, \u001b[39m512\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device), torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m, \u001b[39m13824\u001b[39;49m, \u001b[39m512\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device), torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m, \u001b[39m13824\u001b[39;49m, \u001b[39m512\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device), torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m, \u001b[39m13824\u001b[39;49m, \u001b[39m512\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device)])\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/CT-CLIP/CT_CLIP/ct_clip/ct_clip_seg.py:126\u001b[0m, in \u001b[0;36mseg_model.forward\u001b[0;34m(self, image, hidden_state)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, image, hidden_state):\n\u001b[0;32m--> 126\u001b[0m     enc1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder1(image)\n\u001b[1;32m    127\u001b[0m     enc2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_feat(hidden_state[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeat_size))\n\u001b[1;32m    128\u001b[0m     enc3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_feat(hidden_state[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeat_size))\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/monai/networks/blocks/unetr_block.py:259\u001b[0m, in \u001b[0;36mUnetrBasicBlock.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inp):\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer(inp)\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/monai/networks/blocks/dynunet_block.py:100\u001b[0m, in \u001b[0;36mUnetResBlock.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inp):\n\u001b[1;32m     99\u001b[0m     residual \u001b[39m=\u001b[39m inp\n\u001b[0;32m--> 100\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(inp)\n\u001b[1;32m    101\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(out)\n\u001b[1;32m    102\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlrelu(out)\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/conv.py:725\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.conda/envs/ct_rate/lib/python3.10/site-packages/torch/nn/modules/conv.py:720\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[1;32m    710\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    711\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    719\u001b[0m     )\n\u001b[0;32m--> 720\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(\n\u001b[1;32m    721\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[1;32m    722\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 512, 3, 3, 3], expected input[1, 1, 240, 480, 480] to have 512 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "model(torch.randn(1, 1, 240, 480, 480).to(device), [torch.randn(1, 13824, 512).to(device), torch.randn(1, 13824, 512).to(device), torch.randn(1, 13824, 512).to(device), torch.randn(1, 13824, 512).to(device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter CHeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:261: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:391: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/CT-CLIP/CT_CLIP/ct_clip/ct_clip.py:596: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt = torch.load(str(path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CTCLIP(\n",
       "  (text_transformer): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (visual_transformer): CTViT(\n",
       "    (spatial_rel_pos_bias): ContinuousPositionBias(\n",
       "      (net): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (2): Linear(in_features=512, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (to_patch_emb_first_frame): Sequential(\n",
       "      (0): Rearrange('b c 1 (h p1) (w p2) -> b 1 h w (c p1 p2)', p1=20, p2=20)\n",
       "      (1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Linear(in_features=400, out_features=512, bias=True)\n",
       "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (to_patch_emb): Sequential(\n",
       "      (0): Rearrange('b c (t pt) (h p1) (w p2) -> b t h w (c pt p1 p2)', p1=20, p2=20, pt=10)\n",
       "      (1): LayerNorm((4000,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Linear(in_features=4000, out_features=512, bias=True)\n",
       "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (enc_spatial_transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x ModuleList(\n",
       "          (0): PEG(\n",
       "            (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "            (context_norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "          )\n",
       "          (2): None\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "            (2): GEGLU()\n",
       "            (3): Dropout(p=0.0, inplace=False)\n",
       "            (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm()\n",
       "    )\n",
       "    (enc_temporal_transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x ModuleList(\n",
       "          (0): PEG(\n",
       "            (dsconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=512)\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "            (context_norm): LayerNorm()\n",
       "            (to_q): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=256, out_features=512, bias=False)\n",
       "          )\n",
       "          (2): None\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=512, out_features=2730, bias=False)\n",
       "            (2): GEGLU()\n",
       "            (3): Dropout(p=0.0, inplace=False)\n",
       "            (4): Linear(in_features=1365, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm()\n",
       "    )\n",
       "    (vq): VectorQuantize(\n",
       "      (project_in): Identity()\n",
       "      (project_out): Identity()\n",
       "      (_codebook): CosineSimCodebook()\n",
       "    )\n",
       "    (to_pixels_first_frame): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=400, bias=True)\n",
       "      (1): Rearrange('b 1 h w (c p1 p2) -> b c 1 (h p1) (w p2)', p1=20, p2=20)\n",
       "    )\n",
       "    (to_pixels): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=4000, bias=True)\n",
       "      (1): Rearrange('b t h w (c pt p1 p2) -> b c (t pt) (h p1) (w p2)', p1=20, p2=20, pt=10)\n",
       "    )\n",
       "  )\n",
       "  (to_text_latent): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (to_visual_latent): Linear(in_features=294912, out_features=512, bias=False)\n",
       "  (to_text_latent_extra): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (to_visual_latent_extra): Linear(in_features=294912, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import Adam, AdamW\n",
    "from torchinfo import summary\n",
    "\n",
    "from utils import make_time_bins\n",
    "from utils import encode_survival, mtlr_neg_log_likelihood, make_optimizer\n",
    "from utils import mtlr_survival, mtlr_risk, roc_auc_at_times, brier_score_at_times\n",
    "from prognosis_model import model_lora_again\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "\n",
    "\n",
    "from ct_clip import CTCLIP\n",
    "from transformer_maskgit import CTViT\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from lifelines.utils import concordance_index\n",
    "from data_inference_hector import Hector_Dataset_lora\n",
    "\n",
    "from pycox.models import CoxPH, MTLR, DeepHitSingle\n",
    "from pycox import models\n",
    "\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.argv = ['']\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed) \n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('microsoft/BiomedVLP-CXR-BERT-specialized',do_lower_case=True)\n",
    "text_encoder = BertModel.from_pretrained(\"microsoft/BiomedVLP-CXR-BERT-specialized\")\n",
    "\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "text_encoder.to(device)\n",
    "\n",
    "image_encoder = CTViT(\n",
    "    dim = 512,\n",
    "    codebook_size = 8192,\n",
    "    image_size = 480,\n",
    "    patch_size = 20,\n",
    "    temporal_patch_size = 10,\n",
    "    spatial_depth = 4,\n",
    "    temporal_depth = 4,\n",
    "    dim_head = 32,\n",
    "    heads = 8\n",
    ")\n",
    "\n",
    "image_encoder.to(device)\n",
    "\n",
    "clip = CTCLIP(\n",
    "    image_encoder = image_encoder,\n",
    "    text_encoder = text_encoder,\n",
    "    dim_image = 294912,\n",
    "    dim_text = 768,\n",
    "    dim_latent = 512,\n",
    "    extra_latent_projection = False,         # whether to use separate projections for text-to-image vs image-to-text comparisons (CLOOB)\n",
    "    use_mlm=False,\n",
    "    downsample_image_embeds = False,\n",
    "    use_all_token_embeds = False,\n",
    ")\n",
    "\n",
    "clip.load(\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/CT-CLIP_v2.pt\")\n",
    "clip.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammadqazi/.conda/envs/ct_rate/lib/python3.10/site-packages/pycox/preprocessing/discretization.py:37: UserWarning: cuts are not unique, continue with 10 cuts instead of 12\n",
      "  warnings.warn(f\"cuts are not unique, continue with {len(cuts)} cuts instead of {num}\")\n"
     ]
    }
   ],
   "source": [
    "target = [\n",
    "    \"to_q\", \"to_kv\", \"to_out\"\n",
    "    # \"query\", \"key\", \"value\"\n",
    "    ]\n",
    "peft_config = LoraConfig(\n",
    "    inference_mode=False, r=2, lora_alpha=32, lora_dropout=0.2, target_modules=target\n",
    ")\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Training Script')\n",
    "parser.add_argument('--name', type=str, default='dummy', help='Name of the experiment')\n",
    "parser.add_argument('--method', type=str, default='mtlr', help='whether to use mtlr or deephit')\n",
    "parser.add_argument('--num_time_bins', type=int, default=12, help='NUmber of time bins')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "model = model_lora_again(clip, device, peft_config, 12)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "hect_dataset = Hector_Dataset_lora(data_folder = \"/share/sda/mohammadqazi/project/hector/pre_processed/\",  \n",
    "            csv_file =\"/share/sda/mohammadqazi/project/CTscan_prognosis_VLM-main/docs/TNM_hector_prompts.csv\", args=args)\n",
    "\n",
    "train_dataset, test_dataset = hect_dataset.train_val_split(fold=0)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================================================================================================\n",
       "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Trainable\n",
       "================================================================================================================================================================\n",
       "model_lora_again                                             [4, 1, 240, 480, 480]     [4, 12]                   --                        Partial\n",
       "├─CTCLIP: 1-1                                                --                        [4, 24, 24, 512]          302,776,321               Partial\n",
       "│    └─BertModel: 2-1                                        [4, 512]                  [4, 768]                  --                        False\n",
       "│    │    └─BertEmbeddings: 3-1                              --                        [4, 512, 768]             --                        False\n",
       "│    │    │    └─Embedding: 4-1                              [4, 512]                  [4, 512, 768]             (23,440,896)              False\n",
       "│    │    │    └─Embedding: 4-2                              [4, 512]                  [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    └─Embedding: 4-3                              [1, 512]                  [1, 512, 768]             (393,216)                 False\n",
       "│    │    │    └─LayerNorm: 4-4                              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    └─Dropout: 4-5                                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    └─BertEncoder: 3-2                                 [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    └─ModuleList: 4-6                             --                        --                        --                        False\n",
       "│    │    │    │    └─BertLayer: 5-1                         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-1                [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-1       [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-1             [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-2             [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-3             [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-4            [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-2          [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-5             [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-6            [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-7          [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-2             [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-3                  [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-4          [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-3                   [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-5                  [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-6                 [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-7               [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-2                         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-4                [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-8       [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-8             [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-9             [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-10            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-11           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-9          [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-12            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-13           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-14         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-5             [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-10                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-11         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-6                   [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-12                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-13                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-14              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-3                         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-7                [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-15      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-15            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-16            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-17            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-18           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-16         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-19            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-20           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-21         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-8             [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-17                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-18         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-9                   [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-19                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-20                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-21              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-4                         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-10               [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-22      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-22            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-23            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-24            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-25           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-23         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-26            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-27           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-28         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-11            [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-24                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-25         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-12                  [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-26                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-27                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-28              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-5                         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-13               [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-29      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-29            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-30            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-31            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-32           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-30         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-33            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-34           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-35         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-14            [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-31                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-32         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-15                  [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-33                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-34                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-35              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-6                         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-16               [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-36      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-36            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-37            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-38            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-39           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-37         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-40            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-41           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-42         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-17            [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-38                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-39         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-18                  [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-40                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-41                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-42              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-7                         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-19               [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-43      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-43            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-44            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-45            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-46           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-44         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-47            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-48           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-49         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-20            [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-45                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-46         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-21                  [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-47                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-48                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-49              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-8                         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-22               [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-50      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-50            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-51            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-52            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-53           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-51         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-54            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-55           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-56         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-23            [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-52                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-53         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-24                  [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-54                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-55                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-56              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-9                         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-25               [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-57      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-57            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-58            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-59            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-60           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-58         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-61            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-62           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-63         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-26            [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-59                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-60         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-27                  [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-61                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-62                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-63              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-10                        [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-28               [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-64      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-64            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-65            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-66            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-67           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-65         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-68            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-69           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-70         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-29            [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-66                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-67         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-30                  [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-68                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-69                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-70              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-11                        [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-31               [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-71      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-71            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-72            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-73            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-74           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-72         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-75            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-76           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-77         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-32            [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-73                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-74         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-33                  [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-75                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-76                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-77              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    └─BertLayer: 5-12                        [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    └─BertAttention: 6-34               [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─BertSelfAttention: 7-78      [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-78            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-79            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-80            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-81           [4, 12, 512, 512]         [4, 12, 512, 512]         --                        --\n",
       "│    │    │    │    │    │    └─BertSelfOutput: 7-79         [4, 512, 768]             [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    │    └─Linear: 8-82            [4, 512, 768]             [4, 512, 768]             (590,592)                 False\n",
       "│    │    │    │    │    │    │    └─Dropout: 8-83           [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    │    └─LayerNorm: 8-84         [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    │    │    │    └─BertIntermediate: 6-35            [4, 512, 768]             [4, 512, 3072]            --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-80                 [4, 512, 768]             [4, 512, 3072]            (2,362,368)               False\n",
       "│    │    │    │    │    │    └─GELUActivation: 7-81         [4, 512, 3072]            [4, 512, 3072]            --                        --\n",
       "│    │    │    │    │    └─BertOutput: 6-36                  [4, 512, 3072]            [4, 512, 768]             --                        False\n",
       "│    │    │    │    │    │    └─Linear: 7-82                 [4, 512, 3072]            [4, 512, 768]             (2,360,064)               False\n",
       "│    │    │    │    │    │    └─Dropout: 7-83                [4, 512, 768]             [4, 512, 768]             --                        --\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-84              [4, 512, 768]             [4, 512, 768]             (1,536)                   False\n",
       "│    │    └─BertPooler: 3-3                                  [4, 512, 768]             [4, 768]                  --                        False\n",
       "│    │    │    └─Linear: 4-7                                 [4, 768]                  [4, 768]                  (590,592)                 False\n",
       "│    │    │    └─Tanh: 4-8                                   [4, 768]                  [4, 768]                  --                        --\n",
       "│    └─CTViT: 2-2                                            [4, 1, 240, 480, 480]     [4, 24, 24, 24, 512]      13,034,832                Partial\n",
       "│    │    └─Sequential: 3-4                                  [4, 1, 240, 480, 480]     [4, 24, 24, 24, 512]      --                        False\n",
       "│    │    │    └─Rearrange: 4-9                              [4, 1, 240, 480, 480]     [4, 24, 24, 24, 4000]     --                        --\n",
       "│    │    │    └─LayerNorm: 4-10                             [4, 24, 24, 24, 4000]     [4, 24, 24, 24, 4000]     (8,000)                   False\n",
       "│    │    │    └─Linear: 4-11                                [4, 24, 24, 24, 4000]     [4, 24, 24, 24, 512]      (2,048,512)               False\n",
       "│    │    │    └─LayerNorm: 4-12                             [4, 24, 24, 24, 512]      [4, 24, 24, 24, 512]      (1,024)                   False\n",
       "│    │    └─ContinuousPositionBias: 3-5                      --                        [8, 576, 576]             --                        False\n",
       "│    │    │    └─ModuleList: 4-13                            --                        --                        --                        False\n",
       "│    │    │    │    └─Sequential: 5-13                       [576, 576, 2]             [576, 576, 512]           --                        False\n",
       "│    │    │    │    │    └─Linear: 6-37                      [576, 576, 2]             [576, 576, 512]           (1,536)                   False\n",
       "│    │    │    │    │    └─LeakyReLU: 6-38                   [576, 576, 512]           [576, 576, 512]           --                        --\n",
       "│    │    │    │    └─Sequential: 5-14                       [576, 576, 512]           [576, 576, 512]           --                        False\n",
       "│    │    │    │    │    └─Linear: 6-39                      [576, 576, 512]           [576, 576, 512]           (262,656)                 False\n",
       "│    │    │    │    │    └─LeakyReLU: 6-40                   [576, 576, 512]           [576, 576, 512]           --                        --\n",
       "│    │    │    │    └─Linear: 5-15                           [576, 576, 512]           [576, 576, 8]             (4,104)                   False\n",
       "│    │    └─Transformer: 3-6                                 [96, 576, 512]            [96, 576, 512]            --                        Partial\n",
       "│    │    │    └─ModuleList: 4-14                            --                        --                        --                        Partial\n",
       "│    │    │    │    └─ModuleList: 5-16                       --                        --                        --                        Partial\n",
       "│    │    │    │    │    └─PEG: 6-41                         [96, 576, 512]            [96, 576, 512]            --                        False\n",
       "│    │    │    │    │    │    └─Conv3d: 7-85                 [4, 512, 26, 26, 26]      [4, 512, 24, 24, 24]      (14,336)                  False\n",
       "│    │    │    │    │    └─Attention: 6-42                   [96, 576, 512]            [96, 576, 512]            576                       Partial\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-86              [96, 576, 512]            [96, 576, 512]            (512)                     False\n",
       "│    │    │    │    │    │    └─Linear: 7-87                 [96, 576, 512]            [96, 576, 256]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-85            [96, 576, 512]            [96, 576, 256]            (131,072)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-86        --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-1       [96, 576, 512]            [96, 576, 512]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-87        --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-2        [96, 576, 512]            [96, 576, 2]              1,024                     True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-88        --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-3        [96, 576, 2]              [96, 576, 256]            512                       True\n",
       "│    │    │    │    │    │    └─Linear: 7-88                 [96, 576, 512]            [96, 576, 512]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-89            [96, 576, 512]            [96, 576, 512]            (262,144)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-90        --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-4       [96, 576, 512]            [96, 576, 512]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-91        --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-5        [96, 576, 512]            [96, 576, 2]              1,024                     True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-92        --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-6        [96, 576, 2]              [96, 576, 512]            1,024                     True\n",
       "│    │    │    │    │    │    └─Dropout: 7-89                [96, 8, 576, 576]         [96, 8, 576, 576]         --                        --\n",
       "│    │    │    │    │    │    └─Linear: 7-90                 [96, 576, 256]            [96, 576, 512]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-93            [96, 576, 256]            [96, 576, 512]            (131,072)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-94        --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-7       [96, 576, 256]            [96, 576, 256]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-95        --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-8        [96, 576, 256]            [96, 576, 2]              512                       True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-96        --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-9        [96, 576, 2]              [96, 576, 512]            1,024                     True\n",
       "│    │    │    │    │    └─Sequential: 6-43                  [96, 576, 512]            [96, 576, 512]            --                        False\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-91              [96, 576, 512]            [96, 576, 512]            (1,024)                   False\n",
       "│    │    │    │    │    │    └─Linear: 7-92                 [96, 576, 512]            [96, 576, 2730]           (1,397,760)               False\n",
       "│    │    │    │    │    │    └─GEGLU: 7-93                  [96, 576, 2730]           [96, 576, 1365]           --                        --\n",
       "│    │    │    │    │    │    └─Dropout: 7-94                [96, 576, 1365]           [96, 576, 1365]           --                        --\n",
       "│    │    │    │    │    │    └─Linear: 7-95                 [96, 576, 1365]           [96, 576, 512]            (698,880)                 False\n",
       "│    │    │    │    └─ModuleList: 5-17                       --                        --                        --                        Partial\n",
       "│    │    │    │    │    └─PEG: 6-44                         [96, 576, 512]            [96, 576, 512]            --                        False\n",
       "│    │    │    │    │    │    └─Conv3d: 7-96                 [4, 512, 26, 26, 26]      [4, 512, 24, 24, 24]      (14,336)                  False\n",
       "│    │    │    │    │    └─Attention: 6-45                   [96, 576, 512]            [96, 576, 512]            576                       Partial\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-97              [96, 576, 512]            [96, 576, 512]            (512)                     False\n",
       "│    │    │    │    │    │    └─Linear: 7-98                 [96, 576, 512]            [96, 576, 256]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-97            [96, 576, 512]            [96, 576, 256]            (131,072)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-98        --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-10      [96, 576, 512]            [96, 576, 512]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-99        --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-11       [96, 576, 512]            [96, 576, 2]              1,024                     True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-100       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-12       [96, 576, 2]              [96, 576, 256]            512                       True\n",
       "│    │    │    │    │    │    └─Linear: 7-99                 [96, 576, 512]            [96, 576, 512]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-101           [96, 576, 512]            [96, 576, 512]            (262,144)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-102       --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-13      [96, 576, 512]            [96, 576, 512]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-103       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-14       [96, 576, 512]            [96, 576, 2]              1,024                     True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-104       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-15       [96, 576, 2]              [96, 576, 512]            1,024                     True\n",
       "│    │    │    │    │    │    └─Dropout: 7-100               [96, 8, 576, 576]         [96, 8, 576, 576]         --                        --\n",
       "│    │    │    │    │    │    └─Linear: 7-101                [96, 576, 256]            [96, 576, 512]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-105           [96, 576, 256]            [96, 576, 512]            (131,072)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-106       --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-16      [96, 576, 256]            [96, 576, 256]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-107       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-17       [96, 576, 256]            [96, 576, 2]              512                       True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-108       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-18       [96, 576, 2]              [96, 576, 512]            1,024                     True\n",
       "│    │    │    │    │    └─Sequential: 6-46                  [96, 576, 512]            [96, 576, 512]            --                        False\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-102             [96, 576, 512]            [96, 576, 512]            (1,024)                   False\n",
       "│    │    │    │    │    │    └─Linear: 7-103                [96, 576, 512]            [96, 576, 2730]           (1,397,760)               False\n",
       "│    │    │    │    │    │    └─GEGLU: 7-104                 [96, 576, 2730]           [96, 576, 1365]           --                        --\n",
       "│    │    │    │    │    │    └─Dropout: 7-105               [96, 576, 1365]           [96, 576, 1365]           --                        --\n",
       "│    │    │    │    │    │    └─Linear: 7-106                [96, 576, 1365]           [96, 576, 512]            (698,880)                 False\n",
       "│    │    │    │    └─ModuleList: 5-18                       --                        --                        --                        Partial\n",
       "│    │    │    │    │    └─PEG: 6-47                         [96, 576, 512]            [96, 576, 512]            --                        False\n",
       "│    │    │    │    │    │    └─Conv3d: 7-107                [4, 512, 26, 26, 26]      [4, 512, 24, 24, 24]      (14,336)                  False\n",
       "│    │    │    │    │    └─Attention: 6-48                   [96, 576, 512]            [96, 576, 512]            576                       Partial\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-108             [96, 576, 512]            [96, 576, 512]            (512)                     False\n",
       "│    │    │    │    │    │    └─Linear: 7-109                [96, 576, 512]            [96, 576, 256]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-109           [96, 576, 512]            [96, 576, 256]            (131,072)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-110       --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-19      [96, 576, 512]            [96, 576, 512]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-111       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-20       [96, 576, 512]            [96, 576, 2]              1,024                     True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-112       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-21       [96, 576, 2]              [96, 576, 256]            512                       True\n",
       "│    │    │    │    │    │    └─Linear: 7-110                [96, 576, 512]            [96, 576, 512]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-113           [96, 576, 512]            [96, 576, 512]            (262,144)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-114       --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-22      [96, 576, 512]            [96, 576, 512]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-115       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-23       [96, 576, 512]            [96, 576, 2]              1,024                     True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-116       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-24       [96, 576, 2]              [96, 576, 512]            1,024                     True\n",
       "│    │    │    │    │    │    └─Dropout: 7-111               [96, 8, 576, 576]         [96, 8, 576, 576]         --                        --\n",
       "│    │    │    │    │    │    └─Linear: 7-112                [96, 576, 256]            [96, 576, 512]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-117           [96, 576, 256]            [96, 576, 512]            (131,072)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-118       --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-25      [96, 576, 256]            [96, 576, 256]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-119       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-26       [96, 576, 256]            [96, 576, 2]              512                       True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-120       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-27       [96, 576, 2]              [96, 576, 512]            1,024                     True\n",
       "│    │    │    │    │    └─Sequential: 6-49                  [96, 576, 512]            [96, 576, 512]            --                        False\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-113             [96, 576, 512]            [96, 576, 512]            (1,024)                   False\n",
       "│    │    │    │    │    │    └─Linear: 7-114                [96, 576, 512]            [96, 576, 2730]           (1,397,760)               False\n",
       "│    │    │    │    │    │    └─GEGLU: 7-115                 [96, 576, 2730]           [96, 576, 1365]           --                        --\n",
       "│    │    │    │    │    │    └─Dropout: 7-116               [96, 576, 1365]           [96, 576, 1365]           --                        --\n",
       "│    │    │    │    │    │    └─Linear: 7-117                [96, 576, 1365]           [96, 576, 512]            (698,880)                 False\n",
       "│    │    │    │    └─ModuleList: 5-19                       --                        --                        --                        Partial\n",
       "│    │    │    │    │    └─PEG: 6-50                         [96, 576, 512]            [96, 576, 512]            --                        False\n",
       "│    │    │    │    │    │    └─Conv3d: 7-118                [4, 512, 26, 26, 26]      [4, 512, 24, 24, 24]      (14,336)                  False\n",
       "│    │    │    │    │    └─Attention: 6-51                   [96, 576, 512]            [96, 576, 512]            576                       Partial\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-119             [96, 576, 512]            [96, 576, 512]            (512)                     False\n",
       "│    │    │    │    │    │    └─Linear: 7-120                [96, 576, 512]            [96, 576, 256]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-121           [96, 576, 512]            [96, 576, 256]            (131,072)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-122       --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-28      [96, 576, 512]            [96, 576, 512]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-123       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-29       [96, 576, 512]            [96, 576, 2]              1,024                     True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-124       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-30       [96, 576, 2]              [96, 576, 256]            512                       True\n",
       "│    │    │    │    │    │    └─Linear: 7-121                [96, 576, 512]            [96, 576, 512]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-125           [96, 576, 512]            [96, 576, 512]            (262,144)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-126       --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-31      [96, 576, 512]            [96, 576, 512]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-127       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-32       [96, 576, 512]            [96, 576, 2]              1,024                     True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-128       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-33       [96, 576, 2]              [96, 576, 512]            1,024                     True\n",
       "│    │    │    │    │    │    └─Dropout: 7-122               [96, 8, 576, 576]         [96, 8, 576, 576]         --                        --\n",
       "│    │    │    │    │    │    └─Linear: 7-123                [96, 576, 256]            [96, 576, 512]            --                        Partial\n",
       "│    │    │    │    │    │    │    └─Linear: 8-129           [96, 576, 256]            [96, 576, 512]            (131,072)                 False\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-130       --                        --                        --                        --\n",
       "│    │    │    │    │    │    │    │    └─Dropout: 9-34      [96, 576, 256]            [96, 576, 256]            --                        --\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-131       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-35       [96, 576, 256]            [96, 576, 2]              512                       True\n",
       "│    │    │    │    │    │    │    └─ModuleDict: 8-132       --                        --                        --                        True\n",
       "│    │    │    │    │    │    │    │    └─Linear: 9-36       [96, 576, 2]              [96, 576, 512]            1,024                     True\n",
       "│    │    │    │    │    └─Sequential: 6-52                  [96, 576, 512]            [96, 576, 512]            --                        False\n",
       "│    │    │    │    │    │    └─LayerNorm: 7-124             [96, 576, 512]            [96, 576, 512]            (1,024)                   False\n",
       "│    │    │    │    │    │    └─Linear: 7-125                [96, 576, 512]            [96, 576, 2730]           (1,397,760)               False\n",
       "│    │    │    │    │    │    └─GEGLU: 7-126                 [96, 576, 2730]           [96, 576, 1365]           --                        --\n",
       "│    │    │    │    │    │    └─Dropout: 7-127               [96, 576, 1365]           [96, 576, 1365]           --                        --\n",
       "│    │    │    │    │    │    └─Linear: 7-128                [96, 576, 1365]           [96, 576, 512]            (698,880)                 False\n",
       "│    │    │    └─LayerNorm: 4-15                             [96, 576, 512]            [96, 576, 512]            (512)                     False\n",
       "├─AdaptiveAvgPool2d: 1-2                                     [4, 512, 24, 24]          [4, 512, 1, 1]            --                        --\n",
       "├─Sequential: 1-3                                            [4, 512]                  [4, 512]                  --                        True\n",
       "│    └─Linear: 2-3                                           [4, 512]                  [4, 512]                  262,656                   True\n",
       "│    └─GELU: 2-4                                             [4, 512]                  [4, 512]                  --                        --\n",
       "│    └─Linear: 2-5                                           [4, 512]                  [4, 512]                  262,656                   True\n",
       "│    └─LayerNorm: 2-6                                        [4, 512]                  [4, 512]                  1,024                     True\n",
       "├─Sequential: 1-4                                            [4, 768]                  [4, 512]                  --                        True\n",
       "│    └─Linear: 2-7                                           [4, 768]                  [4, 512]                  393,728                   True\n",
       "│    └─GELU: 2-8                                             [4, 512]                  [4, 512]                  --                        --\n",
       "│    └─Linear: 2-9                                           [4, 512]                  [4, 512]                  262,656                   True\n",
       "│    └─LayerNorm: 2-10                                       [4, 512]                  [4, 512]                  1,024                     True\n",
       "├─Sequential: 1-5                                            [4, 1024]                 [4, 128]                  --                        True\n",
       "│    └─Linear: 2-11                                          [4, 1024]                 [4, 512]                  524,800                   True\n",
       "│    └─ReLU: 2-12                                            [4, 512]                  [4, 512]                  --                        --\n",
       "│    └─Linear: 2-13                                          [4, 512]                  [4, 128]                  65,664                    True\n",
       "├─Linear: 1-6                                                [4, 128]                  [4, 12]                   1,548                     True\n",
       "================================================================================================================================================================\n",
       "Total params: 439,965,477\n",
       "Trainable params: 1,816,716\n",
       "Non-trainable params: 438,148,761\n",
       "Total mult-adds (G): 4.79\n",
       "================================================================================================================================================================\n",
       "Input size (MB): 884.79\n",
       "Forward/backward pass size (MB): 19885.08\n",
       "Params size (MB): 496.61\n",
       "Estimated Total Size (MB): 21266.47\n",
       "================================================================================================================================================================"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_emb, text_emb, relapse, RFS, _, _, _ = next(iter(train_loader))\n",
    "img_emb = img_emb.to(device)\n",
    "text_tokens=tokenizer(text_emb, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512).to(device)\n",
    "relapse = relapse.to(device)\n",
    "RFS = RFS.to(device)\n",
    "summary(model, input_data=[img_emb, text_tokens ], depth=12, col_names=[\"input_size\", \"output_size\", \"num_params\", 'trainable'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mnamed_parameters():\n\u001b[1;32m      2\u001b[0m     \u001b[39mif\u001b[39;00m param\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m      3\u001b[0m         \u001b[39mprint\u001b[39m(name, param\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct_prog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
